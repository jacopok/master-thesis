\documentclass[main.tex]{subfiles}
\begin{document}

\chapter{Gravitational wave theory}

\section{Linearized gravity}

% We give here a brief overview of , roughly following the path taken by \textcite[chapter 1]{maggioreGravitationalWavesVolume2007}.
The simplest way to discuss gravitational radiation is to consider linearized gravity on a flat Minkowskian background.

This means that we assume that our spacetime admits a reference frame for which the metric is in the form 
%
\begin{align}
g_{\mu \nu } = \eta_{\mu \nu } + h_{\mu \nu }
\,,
\end{align}
%
where the value of the components \(h_{\mu \nu }\) is small enough that we can work to first order in them --- throughout this section we shall neglect second- and higher-order corrections in the perturbation.s
We work in this \emph{global inertial frame}. 

In order to study the evolution of the perturbation \(h_{\mu \nu }\) we need to solve the Einstein Field Equations for it to linear order. 
In a vacuum, they can be written as 
%
\begin{align}
G_{\mu \nu } &= R_{\mu \nu} - \frac{1}{2} \eta_{\mu \nu } R  = 0 \\
R_{\mu \nu } &= g^{\alpha \beta } R_{\alpha \mu \beta  \nu }   \\
R &= g^{\mu \nu } R_{\mu \nu }
\,,
\end{align}
%
where \(R_{\alpha \mu \beta \nu } \sim \partial \Gamma + \Gamma \Gamma \) is the Riemann tensor, which is written in terms of derivatives and squares of Christoffel symbols \(\Gamma \): 
%
\begin{align}
\Gamma^{\rho }_{\mu \nu } 
&= \frac{1}{2} g^{\rho \lambda } 
\qty( \partial_{\mu } g_{\nu \lambda } + \partial_{\nu } g_{\lambda \mu } - \partial_{\lambda } g_{\mu \nu }) \\
&= \frac{1}{2} \eta ^{\rho \lambda } 
\qty( \partial_{\mu } h_{\nu \lambda } + \partial_{\nu } h_{\lambda \mu } - \partial_{\lambda } h_{\mu \nu }) 
\marginnote{We use the fact that \(\partial \eta = 0\), and keep only linear order terms.}
\,.
\end{align}

Since the Christoffel symbols are of first order in the perturbation, the term \(\Gamma \Gamma \) in the Riemann tensor is of second order and can be neglected. 
Therefore, the relevant components are 
%
\begin{align}
R_{\mu \nu \rho \sigma } = 2\eta_{\mu \lambda } \Gamma^{\lambda }_{\nu [\sigma , \rho ]}  = h_{\mu [\sigma , \rho] \nu } 
- h_{\nu [\sigma , \rho ] \mu  }
\,,
\end{align}
%
which gives us the following expression for the Ricci tensor: 
%
\begin{align}
R_{\mu \nu } = \frac{1}{2}
\qty( 
    h^{\sigma }{}_{\mu, \sigma \nu  } +
    h^{\sigma }{}_{\nu , \sigma \mu } - 
    h_{, \mu \nu  } -  
    \square h_{\mu \nu } 
)
\,,
\end{align}
%
where \(h = \eta^{\mu \nu } h_{\mu \nu }\) is the trace of the perturbation (computed with respect to the flat metric), while \(\square = \eta^{\mu \nu } \partial_{\mu } \partial_{\nu }\) is the flat space d'Alambertian. 

This, in turn, allows us to write out the Einstein tensor: 
%
\begin{align}
G_{\mu \nu } = \frac{1}{2} \qty(
    h^{\sigma }{}_{\mu, \sigma \nu  } +
    h^{\sigma }{}_{\nu , \sigma \mu } - 
    h_{, \mu \nu  } -  
    \square h_{\mu \nu } -
    \eta_{\mu \nu } h^{\rho \lambda }{}_{, \rho \lambda } + \eta_{\mu \nu } \square h
)
\,.
\end{align}

This can be greatly simplified with two steps:
first, we change variable from the perturbation \(h_{\mu \nu }\) to the \emph{trace-reversed} perturbation \(\overline{h}_{\mu \nu } = h_{\mu \nu } - \eta_{\mu \nu } h / 2\) --- the name comes from the fact that \(\eta^{\mu \nu } \overline{h}_{\mu \nu } = - h\).

This substitution allows us to write the Einstein tensor as 
%
\begin{align}
G_{\mu \nu } = - \frac{1}{2} \square \overline{h}_{\mu \nu } +  \overline{h}_{\alpha (\mu , \nu )}{}^{\alpha } 
- \frac{1}{2} \eta_{\mu \nu } \overline{h}_{\alpha \beta }{}^{, \alpha \beta }
\,.
\end{align}

We will shortly show that it is possible, as a \emph{gauge choice}, to set the divergence of the trace-reversed perturbation to zero: \(\partial^{\mu } \overline{h}_{\mu \nu }= 0\) (see section \ref{sec:gauge-fixing}). The gauge imposed by this choice is called the \emph{Hilbert Gauge},\footnote{Despite the name, this choice was first suggested by De Sitter to Einstein \cite{kennefickTravelingSpeedThought2007}, who had been previously trying to impose the gauge \(\abs{g}= 1\) \cite[page 688]{1916SPAW.......688E}.} which in terms of the regular perturbation reads 
%
\begin{align} \label{eq:hilbert-gauge}
\partial^{\mu } h_{\mu \nu } - \frac{1}{2} \partial_{\nu } h = 0
\,.
\end{align}

With this choice the Einstein tensor becomes simply 
%
\begin{align}
G_{\mu \nu } = - \frac{1}{2} \square \overline{h}_{\mu \nu }
\,,
\end{align}
%
so the general form of the Einstein equations to linear order will be 
%
%
\boxalign{
\begin{align} \label{eq:wave-equation-einstein}
\square \overline{h}_{\mu \nu }= - 16 \pi G \eval{T_{\mu \nu }}_{\text{linear}}
\,,
\end{align}}
%
where the stress-energy tensor is also computed up to first order in the metric perturbation.

\subsection{Transformations of the perturbation}

The theory of General Relativity is constructed to be invariant under smooth changes of coordinates, which are maps in the form \(x \to x' = x' (x)\) (where \(x'(x)\) is a diffeomorphism\footnote{In the physics parlance this property is known as ``diffeomorphism invariance'', while a mathematician would call the transformations considered ``isometries'', since we ask that they preserve the metric structure of the manifold.}).

Under such a coordinate transformation the metric transforms like any \((0, 2)\) tensor:
%
\begin{align} \label{eq:metric-transformation-general}
g_{\alpha \beta }' ( x' ) = \pdv{x^{ \mu }}{x^{\prime \alpha }} 
\pdv{x^{ \nu }}{x^{\prime \beta }} 
g_{\mu \nu } ( x)
\,.
\end{align}

A general transformation of this kind may break the condition that ``\(g = \eta + h\) where \(h\) is small'', so in order to preserve our framework we restrict ourselves to a smaller class of transformations. 

One possibility is to consider infinitesimal transformations in the form 
%
\begin{align}
x^{\mu } \to x^{\prime \mu } = x^{\mu } + \xi^{\mu } (x)
\,,
\end{align}
%
where \(\xi^{\mu }\) is a vector field such that \(\abs{\partial_{\mu } \xi_{\nu }}\) is small --- specifically, the condition to impose is that the first order in \(\partial_{\mu } \xi_{\nu }\) should match the first order in \(h_{\mu \nu }\). 

This condition is all we need in order to write the transformation law for the perturbation: the full equation reads
%
\begin{align}
\eta_{\mu \nu } ' + h_{\mu \nu }' \approx 
\qty(\delta^{\alpha }_{\mu } - \partial^{\alpha } \xi_\mu ) 
\qty(\delta^{\beta  }_{\nu  } - \partial^{\beta  } \xi_\nu  ) 
\qty(\eta_{\alpha \beta } + h_{\mu \nu })
\marginnote{Used \(1 / (1+x) = 1-x + \order{x^2}\).}
\,,
\end{align}
%
so the zeroth order contribution is \(\eta'_{\mu \nu } = \eta_{\mu \nu }\), while the first order one is 
%

%
\boxalign{
\begin{align} \label{eq:perturbation-transformation-infinitesimal}
h^{\prime }_{\mu \nu } = h_{\mu \nu } - 2 \partial_{(\mu } \xi_{\nu )}
\,,
\end{align}}
%
which is our transformation law for the metric perturbation. 

We will also need a transformation law for the trace-reversed perturbation \(\overline{h}_{\mu \nu }\): the trace transforms as \(h' \to h - 2 \partial_{\mu } \xi^{\mu }\), therefore the required law is 
%
\begin{align} \label{eq:perturbation-transformation-infinitesimal-tracereversed}
\overline{h}'_{\mu \nu } = \overline{h}_{\mu \nu } - 2 \partial_{(\mu } \xi_{\nu )} + \eta_{\mu \nu } \partial_{\alpha } \xi^{\alpha }
\,.
\end{align}


A second class of transformations which can preserve the structure \(g = \eta + h\) is a subset of Lorentz boosts and rotations: substituting \(\pdv*{x^{\mu }}{x^{\prime \nu }} = \Lambda_\nu{}^{\mu }\) into the transformation law \eqref{eq:metric-transformation-general} we find that the flat metric is unchanged, while 
%
\begin{align}
h^{\prime }_{\mu \nu } ( x') = \Lambda_{\mu }{}^{\alpha }
\Lambda_{\nu }{}^{\beta } h_{\alpha \beta }
\,,
\end{align}
%
which may remain in the class of small metric perturbations: this is not guaranteed, but it is true for a certain subset of boosts and for all rotations \cite{maggioreGravitationalWavesVolume2007}. 

Finally, the perturbation is invariant under shifts in the form \(x^{\prime \mu }= x^{\mu } + a^{\mu }\). 

\subsection{Gauge fixing} \label{sec:gauge-fixing}

Now that we know how the perturbation \(h_{\mu \nu }\) transforms under an infinitesimal transformation, we can use this to impose the gauge conditions we want --- specifically, the Hilbert gauge \eqref{eq:hilbert-gauge}.

The way to show that this is possible is to write out the way \(\partial^{\mu } \overline{h}_{\mu \nu }\) transforms for an arbitrary choice of \(\xi \), and to see that with an appropriate choice of \(\xi \) we can always map it to zero. 
The transformation reads 
%
\begin{align}
\partial^{\mu } \overline{h}_{\mu \nu }' &= 
\partial^{\mu } \qty(h_{\mu \nu } - 2 \partial_{(\mu } \xi_{\nu )}) - \frac{1}{2} \partial_{\nu } \qty(\eta^{\alpha \beta } \qty(h_{\alpha \beta } - 2 \partial_{(\alpha } \xi_{\beta )}))  \\
&= \partial^{\mu } \overline{h}_{\mu \nu } - \square \xi_{\nu } - \partial_{\nu } \qty(\partial^{\mu } \xi_{\mu }) + \partial_{\nu } \qty(\partial^{\mu } \xi_{\mu })  \\
&= \partial^{\mu } \overline{h}_{\mu \nu } - \square \xi_{\nu } \overset{!}{=} 0
\,. 
\end{align}

Therefore, from any starting gauge we must only find a \(\xi_{\nu }\) such that \(\partial^{\mu } \overline{h}_{\mu \nu } = \square \xi_{\nu }\), and we will be in the correct gauge. 
This can always be done, since the D'Alambert equation \(\square f = g\) can always be solved for \(f\) --- if we needed to compute \(\xi_{\nu }\) explicitly (which we typically do not) we could use the Green's function \(G(z)\) for the operator, defined by \(\square G(z) = \delta^{(4)} (z)\). 

While the equation is solvable, the solution is not unique: if we were to define an ``inverse'' of the D'Alambertian it would not be a function but a one-to-many relation. 
Specifically, while keeping fixed the value of \(\square \xi_{\nu }\) we can add any function \(\zeta_\nu \) to \(\xi _\nu  \) as long as \(\square \zeta _\nu = 0 \). 
A trivial example is \(\zeta _\nu = \const\), but other wave-like choices are of more interest. 

These still induce a transformation on \(h_{\mu \nu }\) according to the usual law \eqref{eq:perturbation-transformation-infinitesimal}, and they can be used to further specify the form of the gravitational radiation. This is called a \textbf{residual gauge choice}. 

In terms of \textbf{degrees of freedom}, the full perturbation \(h_{\mu \nu }\) starts with 10 as any symmetric 4D, rank-2 tensor; the four Hilbert gauge conditions \eqref{eq:hilbert-gauge} reduce them to 6, while the four residual gauge conditions will allow us, under some specific assumptions,\footnote{The gauge we will impose in the next section can only be imposed in a vacuum, but even in the presence of matter a decomposition of the degrees of freedom of metric perturbations yields two tensorial, propagating ones; four more are present but they do not obey wave-like equations \cite[sec.\ 7.2]{carrollSpacetimeGeometryIntroduction2019}.} to reduce them to 2.

Let us fix the residual gauge in the specific context of a plane wave solution to the wave equation \(\square \overline{h}_{\mu \nu } = 0\).

\subsection{Plane gravitational waves} \label{sec:plane-gws}

A general solution to the wave equation may be written as a superposition of plane waves in the form
%
\begin{align}
\overline{h}_{\mu \nu } = A_{\mu \nu } e^{i k_\alpha x^{\alpha }}
\,,
\end{align}
%
where \(A_{\mu \nu }\) is a constant symmetric tensor.
Let us then consider a single plane wave.

Imposing the wave equation sets \(k_{\alpha } k^{\alpha } = 0\), and the Hilbert gauge \eqref{eq:hilbert-gauge} condition can be written as \(A_{\mu \nu } k^{\mu } = 0\), where \(A = \eta^{\mu \nu } A_{\mu \nu }\). 

In this framework we can impose the residual gauge condition explicitly: a function which satisfies \(\square \zeta_{\mu } = 0\) is \(\zeta_{\mu } = B_{\mu } \exp(i d_\alpha x^{\alpha })\), where \(d_\alpha \) is a null vector (\(d_\alpha d^{\alpha } = 0\)) while \(B_\mu \) is a generic constant vector.

In these terms, the transformation equation \eqref{eq:perturbation-transformation-infinitesimal-tracereversed} reads 
%
\begin{align}
\overline{h}_{\mu \nu } &\to \overline{h}_{\mu \nu } + \qty(- 2 i B_{(\mu } d_{\nu )}  + i \eta_{\mu \nu } B_{\beta } d^{\beta } ) e^{i d_\alpha x^{\alpha }} \\
A_{\mu \nu } e^{i k_\alpha x^{\alpha }} &\to A_{\mu \nu } e^{i k_\alpha x^{\alpha }} + \qty(-2 i B_{(\mu } d_{\nu )} + i \eta_{\mu \nu } B_{\beta } d^{\beta }) e^{i d_\alpha x^{\alpha }} 
\,.
\end{align}

This tells us that if we set the vector \(d_{\alpha }\) to be equal to \(k_\alpha \) the amplitude \(A_{\mu \nu }\) will transform according to the algebraic system
%
\begin{align}
A_{\mu \nu } \to A_{\mu \nu } - 2 i B_{(\mu } k_{\nu )}
\,,
\end{align}
%
which allows us to impose four conditions on \(A_{\mu \nu }\), one for each of the free components of \(B_{\mu }\). 
It is customary to choose \(A = 0 = A_{0 i }\): these are known together as the \ac{TT} gauge. 

The condition \(A = 0\) also means that \(h = 0 = \overline{h}\): thus, form this point onward we can stop distinguishing between \(h_{\mu \nu }\) and  \(\overline{h}_{\mu \nu }\), and for simplicity's sake we write the former. 

If we orient our axes such that \(\vec{k} = k^{i}\) is along the \(\hat{z}\) direction (which means \(k^{\mu } = (k, 0, 0, k)^{\top}\)) the conditions can be written as 
\begin{enumerate}
    \item Hilbert gauge + traceless: \(A_{\mu 0}+ A_{\mu 3} = 0\);
    \item traceless: \(A = - A_{00} + A_{11} + A_{22} + A_{33} = 0 \);
    \item transverse: \(A_{0i} = 0\). 
\end{enumerate}

The Hilbert gauge combined with the transverse conditions show that \(A_{00} = 0\) as well, followed by \(A_{13} = 0\), \(A_{23} = 0\) and \(A_{33} = 0\). 

Finally, the traceless condition imposes \(A_{11} = - A_{22} \).
These conditions tell us that the plane gravitational wave must have the form 
%

%
\boxalign{
\begin{align} \label{eq:TT-gauge-gw}
h_{\mu \nu }^{TT}(x) = \left[\begin{array}{cccc}
0 & 0 & 0 & 0 \\ 
0 & h_+ & h_\times  & 0 \\ 
0 & h_\times  & - h_+ & 0 \\ 
0 & 0 & 0 & 0
\end{array}\right]
\exp(i k_{\alpha } x^{ \alpha })
\,,
\end{align}}
%
where \(h_+ = A_{11} \) and \(h_\times = A_{12} \). 

In a later discussion we will use the fact that a general perturbation \(h_{\mu \nu }\) can be \emph{projected} into the \ac{TT} gauge by using a certain projection tensor \(\Lambda_{ijkl}\); this is not trivial to show, but the general idea follows from a decomposition of the full perturbation into scalar, vector and tensor components \cite[sec.\ 7.2]{carrollSpacetimeGeometryIntroduction2019}.
Specifically, the number of free components before gauge fixing is 4 scalar, 4 vector and 2 tensor components. 
The tensor components are gauge invariant, while the other 8 can each be separately set to zero in an appropriate gauge.
After applying the same decomposition to the stress-energy tensor and writing the Einstein equations we find that the tensor perturbations (which are precisely the \(h_{+}\) and \(h_{ \times }\) polarization degrees of freedom) are the only ones which propagate according to a wave equation. 
The projection, which yields a perturbation with two degrees of freedom, is thus only a way to recover the ``radiative'' part of the metric. 

\subsection{Effect on test masses}

The \ac{TT} gauge we defined has the rather peculiar characteristic of ``moving with the wave'', so that the position of any observer initially at rest (so, such that \(u^{\mu } (\tau = 0 ) = (1, \vec{0})^{\top}\)) is unchanged: the geodesic equation evaluated at \(\tau = 0\) reads
%
\begin{align}
\eval{\dv[2]{x^{\mu }}{\tau}}_{\tau = 0} + \eval{\Gamma^{\mu }_{\nu \rho } u^{\nu } u^{\rho }}_{\tau = 0} &= 0   \\
\eval{\dv[2]{x^{\mu }}{\tau}}_{\tau = 0} &= - \Gamma^{\mu }_{00} = 0 
\,,
\end{align}
%
since the Christoffel symbols computed \(\Gamma^{\mu }_{00}\) with the \ac{TT} gauge perturbation \eqref{eq:TT-gauge-gw} all vanish: \(\Gamma^{\mu }_{00} = \eta^{\mu \nu } \qty( 2 g_{\nu 0,0} - g_{00, \nu }) / 2 =  0\).

Does this mean that gravitational waves are merely an artefact, and have no effect on particles? 
No, since while in the \ac{TT} gauge the \emph{positions} of the points do not change, the \emph{distance} among them does.

In order to understand this effect we can make use of the geodesic deviation equation \cite[section 3.10]{carrollSpacetimeGeometryIntroduction2019}, which states that if we take two geodesics whose four-velocities are both approximately \(u^{\mu }\), separated by a short vector \(\xi ^{\mu }\),\footnote{There is a technical note to be made here: in GR the notion of a vector between two points in the manifold is meaningless, however we can get around this problem by considering a one-parameter family of geodesics, and identifying the separation vector between them to be the tangent vector associated to the parameter.} they might diverge or converge, and the evolution of \(\xi^{\mu }\) will be described by
%
\begin{align}
\ddot{\xi}^{\mu } = R^{\mu }_{\nu \rho \sigma } u^{\nu } u^{\rho } \xi^{\sigma }
\,.
\end{align}

Let us consider the same geodesics as before, whose four-velocity is uniformly \(u^{\mu } \equiv [1, \vec{0}]^{\top}\): the ``acceleration'' will then be given by the matrix product \(R^{\mu }_{00\sigma } \xi^{\sigma }\). 

These components of the Riemann tensor read \cite[eq.\ 7.106]{carrollSpacetimeGeometryIntroduction2019}: 
%
\begin{align}
R^{\mu }_{00 \sigma } = \frac{1}{2} \ddot{h}^{\mu }_{\sigma }
\,.
\end{align}

Therefore, the temporal component of the acceleration is \(\ddot{\xi}^{0} \propto \ddot{h}^{0}_{\sigma } = 0 \), while the spatial components read 
%
\begin{align} \label{eq:tidal-acceleration-TT-gauge}
\ddot{\xi}
^{i} = \frac{1}{2} \ddot{h}^{i}_{j} \xi^{j}
\,.
\end{align}

These equations can then be explicitly solved.
It is important to remark that \(\ddot{\xi }^{i}\) is \emph{not} coordinate acceleration: the points are \emph{stationary} in the \ac{TT} gauge coordinates, but the distance among them changes.
Intuitively, we can interpret this as due to our carefully constructed gauge choice, which was determined through residual gauge, so it satisfied a wave equation \(\square \zeta _\mu =0 \): it precisely oscillates with the wave, allowing the position of any point to not change (to linear order). 
Fortunately \acsp{GW} are physical, so they must still manifest regardless of our gauge, and they do so through the distortion of distances as described here.

\begin{figure}[ht]
\centering
\includegraphics[width=.7\textwidth]{figures/polarizations}
\caption{Polarizations of gravitational waves. Time evolution is represented though transparency: darker ellipses correspond to later points in time. The four cases are described in the text. We stress that in the \ac{TT} gauge the ellipses do not represent changes in coordinate position but only in distance among points. In all cases the starting configuration is circular. The code generating this figure is available \href{https://github.com/jacopok/master-thesis/blob/main/thesis/figures/polarizations.py}{here}.}
\label{fig:polarizations}
\end{figure}

The distances of points at a fixed position (\(x\), \(y\), \(z\)) from the center change (up to a phase) according to the expression 
%
\begin{align}
x (t) &= x_{0} \qty(1 + h_+ e^{i \omega t}) + y_{0} h_\times  e^{i \omega t} \\
y (t) &= y_{0} \qty(1 - h_+ e^{i \omega t}) + x_{0} h_\times  e^{i \omega t} 
\,,
\end{align}
%
which is shown graphically in figure \ref{fig:polarizations} for four configurations: only \(h_+\) or \(h_\times \) being nonzero, or only \(h_R \propto h_+ + i h_\times \) or \(h_L \propto h_+ - i h_\times \) being nonzero. 
The last two are called \emph{circular polarizations}.

This description is not the one an experimentalist might use: if we need to consider the noise due to other sources of gravitation, it is convenient to move from the \ac{TT} gauge to the \emph{proper detector frame}, in which the metric is expanded around a fiducial point of our detector --- for instance, around the beam-splitter in an interferometer.
In such a frame, it can be shown that the effect of \acsp{GW} can be described as a Newtonian force on points a certain distance away from it --- for instance, the mirrors of the interferometer. This comes in at second order in the distance, and it is given by \cite[eq.\ 1.96]{maggioreGravitationalWavesVolume2007}
%
\begin{align}
F_{i} = \frac{m}{2} \ddot{h}_{ij}^{TT} \xi^{j}
\,,
\end{align}
%
which unsurprisingly closely mirrors the \ac{TT} gauge variation of the distance: the physically measurable effect must be independent of gauge choice. 
The reason the \ac{TT} gauge perturbation appears here as well is that the Riemann tensor, which is used in these computations, is \emph{invariant} (a stronger condition than covariant --- the values of the components are actually unchanged) under gauge transformations. 

\subsection{The quadrupole formula}

The lowest order contribution to the generation of gravitational waves can be calculated starting from the linearized Einstein equations \eqref{eq:wave-equation-einstein}. 
The Green's function method for the inversion of the D'Alambertian is a common technique: if we can find a function \(G(z)\) such that \(\square G(z) = \delta^{(4)} (z)\), then we can do the following manipulation (denoting the gravitational constant as \(G_N\) for clarity): 
%
\begin{align}
\square_x \overline{h}_{\mu \nu} (x) &= - 16 \pi G_N T_{\mu \nu } (x)  \\
&= - 16 \pi G_N \int \dd[4]{y} T_{\mu \nu }(y) \delta^{(4)} (x-y)  \\
&= - 16 \pi G_N \int \dd[4]{y} T_{\mu \nu }(y) \square_x G(x-y)  \\
&= \square_x \qty(- 16 \pi G_N \int \dd[4]{y} T_{\mu \nu }(y) G(x-y))  
\marginnote{Removing the D'Alambertian is valid insamuch as it will give us \emph{a} solution for the wave equation, which will not be unique:  \(\square f = \square g\) does not imply \(f = g\), but the reverse is true.} 
\\
\overline{h}_{\mu \nu } &= -16 \pi G_N \int \dd[4]{y} T_{\mu \nu }(y) G(x-y)  
\\
&= 4 G_N \int \dd[3]{y} T_{\mu \nu }(x^{0} - \abs{\vec{x} - \vec{y}}, \vec{y}) \frac{1}{\abs{\vec{x} - \vec{y}}}
\,,
\end{align}
%
where in the last step we introduced the explicit expression for the Green's function of the D'Alambertian: \(G(z) = - \Theta (z^{0}) / 4 \pi \abs{\vec{z}}\)
% \footnote{The square bracket here is the Iverson bracket \cite{knuthTwoNotesNotation1992}, which maps a boolean expression to 1 (if true) or 0 (if false); in this context it is thus equivalent to the Heaviside Theta: \([z^{0}>0] = \Theta (z^{0})\).} 
\cite[eq.\ 3.6]{maggioreGravitationalWavesVolume2007}. 

We then have a formula for the trace-reversed perturbation, and as we discussed in section \ref{sec:plane-gws} far from the source we can recover the \ac{TT} gauge perturbation by projecting this equation thanks to a tensor \(\Lambda_{ij, kl} (\hat{n})\) (we return to \(G \equiv G_N\) denoting the gravitational constant): 
%
\begin{align}
h_{ij}^{TT} (t, \vec{x}) = 4G \Lambda_{ij, kl}(\hat{n}) \int \frac{\dd[3]{y}}{\abs{\vec{x} - \vec{y}}} T_{kl} \qty(t - \abs{\vec{x} - \vec{y}}, \vec{y}) 
\,,
\end{align}
%
where the tensor \(\Lambda \) is constructed to be a projector which sends 2-tensors into the subspace of traceless tensors, which are transverse to the direction defined by \(\hat{n} = \vec{x} / \abs{\vec{x}}\): 
%
\begin{align}
\Lambda_{ij, kl} = P_{ik} P_{jl}- \frac{1}{2} P_{ij} P_{kl} 
\qquad \text{where} \qquad
P_{ ij} = \delta_{ij} - n_i n_j   
\,.
\end{align}

This expression can be further simplified by making use of the assumption that the source is far away: the integral over \(\dd[3]{y}\) ranges over a region which has a maximum size of \(R\), the scale of the source, while the wave is observed at a distance \(r = \abs{\vec{x}} \gg R\). 
This allows us to expand and neglect terms of the order \(R^2 / r^2\) and over;\footnote{
    Specifically, we expand 
    %
    \begin{align}
    \abs{\vec{x} - \vec{y}} = \sqrt{x^2 + y^2 + 2 x \cdot y} 
    = r \sqrt{1 - 2 \frac{\hat{n} \cdot \vec{y}}{r} + \frac{y^2}{r^2}}
    \approx r \qty(1 - 2 \frac{\hat{n} \cdot \vec{y}}{r} + \order{R^2/ r^2})
    \,.
    \end{align}
} the result we get is 
%
\begin{align}
h_{ij}^{TT} = \frac{4 G}{r} \Lambda_{ij, kl} (\hat{n})
\int \dd[3]{y} T_{kl} \qty(t-r + \vec{y}\cdot \hat{n}, \vec{y}) 
\,.
\end{align}

This equation uses the stress-energy tensor as computed without considering the higher-order effects of gravity on matter (this is the meaning of ``linear'' in the linear wave equation \eqref{eq:wave-equation-einstein}); thus it is only a good approximation in the case of objects whose typical scale \(R\) is much larger, than, say, their Schwarzschild radius \(2GM\). 
The problem with this assumption is that it fails to hold precisely for the sources which we are most interested in since, as we shall see, they give out some of the most easily detectable gravitational radiation: binary compact objects near coalescence.\footnote{As we shall discuss later, the amplitude of the waves emitted rises as they get closer and closer; also, \acp{BNS} and \acp{BBH} often reach their peak amplitude in the frequency range where our detectors are most sensitive.
Nevertheless, the ``Newtonian'' stage of the inspiral (a long time before the merger) will be described quite well by the expressions discussed here.}

For a gravitationally bound source like a binary, with total mass \(M = m_1 + m_2 \), reduced mass \(\mu = (m_1^{-1} + m_2^{-1})^{-1}\), moving with speed \(v\) and with a relative separation \(r\), the virial theorem dictates that 
%
\begin{align}
\frac{1}{2} \mu v^2 = \frac{1}{2} G \frac{\mu M}{r} \implies v^2 = \frac{GM}{r} = \frac{R_s}{r} 
\,,
\end{align}
% 
where \(R_s\) is the Schwarzschild radius corresponding to the total mass of the system. 

This means that the source not being very compact\footnote{We are being loose with terminology: the two stars in the binary may be compact themselves, but the system as a whole isn't. } (\(R_s \ll r\)) is equivalent to it moving slowly (\(v \ll 1\)). 
Neither of these assumptions will hold in the end, but since we are using one we should use both. 

In Fourier space, this amounts to saying that the typical frequencies \(\omega \) for which the amplitude of the Fourier transform of the stress-energy tensor is large will satisfy \(\omega \vec{y} \cdot \hat{n} \lesssim \omega R \ll 1\). 
This means that we can expand the exponential in the Fourier transform; in the time domain this amounts to expanding in time around the retarded time \(t - r\): 
%
\begin{align}
T_{kl} (t-r + \vec{y} \cdot \hat{n}, \vec{y}) \approx T_{kl} (t-r, \vec{y}) + \vec{y} \cdot \hat{n} \partial_{t} T_{kl} + \frac{1}{2} (\vec{y} \cdot \hat{n})^2 \partial^2_{tt} T_{kl} + \order{(\vec{y} \cdot \hat{n})^3}
\,.
\end{align}

This allows us to write the resulting wave as a multipole expansion:
%
\begin{align} \label{eq:gw-expansion-moments-stess-tensor}
h_{ij}^{TT} (t, \vec{x}) &= \frac{4G}{r} \Lambda_{ij, kl} \qty(S_{kl} + \sum_{L=1}^{\infty } \frac{1}{L!} \partial_{t}^{L} S_{kl | i_1 \dots i_L} n_{i_1} \dots n_{i_L})
\marginnote{To be computed at redarded time.}
\,,
\end{align}
%
where the moments of the stress tensor \(S_{kl|i_1 \dots i_L}\) are defined as 
%
\begin{align}
S_{kl | i_1 \dots i_L} = \int \dd[3]{y} T_{kl} y_{i_1} \dots y_{i_L}
\,.
\end{align}

We can also analogously calculate moments for the energy density \(T_{00} \), which we denote \(M_{i_1 \dots i_L}\), and for the momentum density \(T_{0i}\), which we denote \(P_{k|i_1 \dots i_L}\). 

With integration by parts combined with the (flat space!) conservation of the stress-energy tensor \(\partial_{\mu } T^{\mu \nu }= 0\) we can relate the \(M\), \(P\) and \(S\) with equations such as \cite[eqs.\ 3.45--51]{maggioreGravitationalWavesVolume2007}
%
\begin{align}
\dot{M} &= 0  \\
\dot{P}_{i} &= 0 \\
\dot{M}_{ij} &= 2 P_{(i|j)}   \\
S_{ij} &= P_{i | j}
\,,
\end{align}
%
where dots denote time derivatives.

These all tell us something interesting: \(\dot{M} = 0\) and \(\dot{P}_{i} = 0\) are energy and momentum conservation, which seem to tell us that there is no energy nor momentum loss from \ac{GW} emission. 
This is an artifact, due to the assumptions of linear theory which neglect back-action on the source; fortunately we will still be able to compute the energy loss of the system even in this approximation.

The second useful fact is \(S_{ij} = \ddot{M}_{ij} / 2\): this allows us to write the lowest-order approximation of the expression of the wave from the source in terms of moments \eqref{eq:gw-expansion-moments-stess-tensor} as 
%
\begin{align}
h_{ij}^{TT}(t, \vec{x}) = \frac{2 G}{r} \Lambda_{ij, kl} \ddot{M}_{kl}
\,,
\end{align}
%
where 
%
\begin{align}
M_{kl}(t-r) = \int \dd[3]{y} T_{00}(t -r, \vec{y}) y_k y_l
\,.
\end{align}

since this expression only depends on the trace-free part of the moment \(M\) we can write it as a function of the traceless \textbf{quadrupole moment} 
%
\begin{align} \label{eq:quadrupole}
Q_{kl} = M_{kl} - \delta_{kl} M_{nn} / 3
= \int \dd[3]{y} \rho (t, \vec{y}) \qty(y^{i } y^{j} - \frac{1}{2} \delta^{ij} y^2)
\,.
\end{align}

This gives rise to the quadrupole formula:
%
\boxalign{
\begin{align} \label{eq:quadrupole-formula}
h_{ij}^{TT}(t, \vec{x}) = \frac{2 G}{r} \Lambda_{ij,kl} \ddot{Q}_{kl}(t-r)
\,.
\end{align}}

\subsection{Energy loss through gravitational radiation}

The problem of quantifying the energy carried by gravitational radiation is thorny \cite[sec.\ 20.4]{misnerGravitation1973}: first of all, there is no universally valid way to split the perturbation from the background in the general case; also, at each point we can always apply the equivalence principle to recover flat spacetime up to first order. 
It is impossible to construct a \emph{local}, gauge invariant stress-energy tensor \(T_{\mu \nu }^{GW}\) for \ac{GW} radiation: the limit of the energy density contained in any volume will always vanish as that volume goes to zero. 

However, we \emph{can} define a tensor through an averaging procedure over many wavelengths and periods of the wave. There are different ways to do so, but a common one is the Landau-Lifshitz pseudotensor: 
%
\begin{align}
t_{\mu \nu } &= - \frac{1}{8 \pi G} \expval{R^{(2)}_{\mu \nu }- \frac{1}{2} \overline{g}_{\mu \nu } R^{(2)}}_{\text{mesoscopic}}  \\
&= \frac{1}{32 \pi G} \expval{\partial_{\mu } h_{\alpha \beta } \partial_{\nu }h^{\alpha \beta }}
\,,
\end{align}
%
where \(R^{(2)}_{\mu \nu }\) and \(R^{(2)}\) are the components of the Ricci tensor and scalar which are quadratic in the perturbation \(h_{\mu \nu }\); \(\overline{g}_{\mu \nu }\) is the background metric, and the averaging procedure is done on scales (wavelengths/periods) which are (much) larger than the typical wavelengths of the gravitational radiation considered, but (much) smaller than the typical wavelengths of the background \cite[sections 1.4.2, 1.4.3]{maggioreGravitationalWavesVolume2007}.

This pseudotensor can be used to describe the way in which, on large enough scales, the presence of \acsp{GW} does indeed curve spacetime.
Also, we can compute the energy flux passing through a surface a large distance from the source: if we use the quadrupole formula \eqref{eq:quadrupole-formula} for the gravitational perturbation, we can give an expression for the emitted power in terms of the third derivatives of the quadrupole as \cite[eq.\ 3.98]{maggioreGravitationalWavesVolume2007} 
%
\begin{align} \label{eq:energy-emission-quadrupole}
\dv{E}{t} = -\frac{G}{5} \expval{ \dot{\ddot{Q}}_{ij} \dot{\ddot{Q}}_{ij}}
\,.
\end{align}

Dimensionally, \(Q \sim \int \dd[3]{y} \rho r^2\) has units of \SI{}{kg m^2}; so \(\dot{\ddot{Q}}\) has units of \(\SI{}{kg m^2 / s^3} = \SI{}{W}\).

This means that the prefactor, which we wrote using \(c=1\), must really be \(G c^{n}/5\) with units of inverse power, which implies \(n = -5\).
Numerically, it is the inverse of \(5c^{5} / G \approx \SI{2e53}{W}\). 
This means that in order for \ac{GW} emission to be efficient we must have a large value for \(\dot{\ddot{Q}}\): let us estimate it in terms of the typical size of the system, \(R\), of its typical velocity \(v = \Omega R\) and of its mass \(M\). 
Each time derivative will roughly correspond to multiplication by a factor \(\Omega \), so \(\dot{\ddot{Q}} \sim \Omega^3 M R^2 = v^3 M / R\).

The power can then be estimated as 
%
\begin{align} \label{eq:energy-emission-estimate}
- \dv{E}{t} \sim \frac{G}{5 c^{5}} v^{6} \frac{M^2}{R^2} 
= \underbrace{\frac{1}{5} \frac{c^{5}}{G}}_{\sim\SI{e52}{W}} \qty( \frac{v}{c})^{6} \qty( \frac{GM}{c^2 R})^2
\,,
\end{align}
%
which tells us that the most significant sources of \ac{GW} will be relativistic and compact.
This prediction has been validated in 2015 with the first detection of \ac{GW} from a \ac{BBH} system \cite{abbottObservationGravitationalWaves2016}, and again in 2017 with the first detection of \ac{GW} from a \ac{BNS} system \cite{abbottGW170817ObservationGravitational2017}. 

\section{Compact binaries} \label{sec:compact-binaries-linear}

We focus our attention towards a pair of inspiraling (compact) objects, which we will initially model as point masses in quasi-circular orbits.
The first thing we need to do is to write an expression the amplitudes in the two polarizations \(h_{+, \times }\) of the waves generated by a generic mass distribution with a mass moment \(M_{ij}\) \cite[eqs.\ 3.67--68]{maggioreGravitationalWavesVolume2007}:\footnote{We could also write these in terms of the traceless quadrupole moment \(Q_{ij}\); we follow the convention set forward by \textcite{maggioreGravitationalWavesVolume2007}.} 
%
\begin{align}
h_{+}(t, \hat{n}) &= \frac{G}{r} \qty(\ddot{M}_{11}' - \ddot{M}_{22}')\\
h_{+}(t, \hat{n}) &= \frac{G}{r} \qty(2\ddot{M}_{12}')
\,,
\end{align}
%
where \(M^{\prime }_{ij}\) are the components of the mass moment tensor in a frame whose \(z'\) axis is aligned to the observation direction.

This frame is not the natural one with which to describe a binary system: typically, we would want to align the \(z\) axis of the coordinates with the rotation axis. 
The rotation matrix between two systems depends on two angles, however one of these is more important than the other: aligning the \(z\) axes can be accomplished by a rotation of angle \(\iota \) (dubbed the \emph{inclination}), while another rotation of angle \(\phi \) is needed in order to align the \(x\) and \(y\) axes as well. 
However, since the system is rotating around its axis in a quasi-circular orbit, the second rotation only amounts to a time shift, an additional phase term in the oscillatory functions. 
For simplicity, we will neglect this phase freedom here and only include a variable phase at the end of the computations.

If the position of the bodies in the center-of-mass frame is 
%
\begin{align}
\vec{x}(t) = R \left[\begin{array}{c}
\cos(\Omega t) \\ 
\sin(\Omega t) \\ 
0
\end{array}\right]
\,,
\end{align}
%
then the mass moments read \(M_{ij} = \mu x_i (t) x_j(t)\) (where \(\mu = m_1 m_2 / (m_1 + m_2 ) \) is the reduced mass of the system), and going through the computation yields \cite[eq.\ 3.332]{maggioreGravitationalWavesVolume2007}
%
\begin{align} \label{eq:binary-waveform-1}
h_{+} (t) &= \underbrace{\frac{4 G \mu \Omega^2 R^2}{r}}_{A} \qty(\frac{1 + \cos^2 \iota }{2}) \cos( 2 \Omega t) 
\\
h_{ \times } (t) &= \underbrace{\frac{4 G \mu \Omega^2 R^2}{r}}_{A} \cos \iota  \sin( 2 \Omega t) 
\\
A &= \frac{4}{r} \qty(\frac{G\mathcal{M}_c}{c^2})^{5/3} \qty(\frac{\pi f _{\text{gw}}}{c})^{2/3} 
\,.
\end{align}

Approximating the motion of the bodies as circular during an orbit is called the \emph{adiabatic approximation}, since it assumes that no energy is lost in each orbit (as that would deform the circle). The variation of the orbital frequency \(\Omega \), which we shall compute shortly, must satisfy \(\dot{\Omega} \ll \Omega^2\). 
This turns out to be a good approximation only for very early stages of the inspiral. 

The last expression we wrote for the amplitude of the emission reintroduces factors of \(c\), and it is expressed in terms of the emission frequency \(f _{\text{gw}} = \omega _{\text{gw}} / 2 \pi = \Omega / \pi \) and of the \emph{chirp mass}
%
\begin{align} \label{eq:chirp-mass}
\mathcal{M}_c = \frac{(m_1 m_2 )^{3/5}}{(m_1 + m_2 )^{1/5}} = \nu^{3/5} M 
\qquad \text{where} \qquad
\nu = \frac{\mu}{M}
\,.
\end{align}

The parameter \(\nu \) is called the \emph{symmetric mass ratio}, and it takes values from \(\nu \to 0\) (one mass vanishing) to \(\nu = 1/4\) (equal masses).

\subsection{Energy evolution}

Combining equations \eqref{eq:binary-waveform-1} with the quadrupole emission formula \eqref{eq:energy-emission-quadrupole} yields an expression for the emitted power as a function of the \ac{GW} frequency
%
\begin{align}
P = \frac{32}{5} \frac{c^{5}}{G} \qty(\frac{G \mathcal{M}_c \omega_{\text{gw}}}{2 c^3})^{10/3}
\,.
\end{align}

This allows us to describe the evolution of the orbit in the adiabatic context: the total energy of the binary system, by the virial theorem combined with Kepler's third law \(\Omega^2 R^3 = G M\), reads 
%
\begin{align}
E = - \frac{G m_1 m_2 }{2R}  = - \frac{G m_1 m_2 }{2} \frac{\Omega^{2/3}}{G^{1/3} M^{1/3}} = - \qty( \frac{G^2 \mathcal{M}_c^{5} \omega^2 _{\text{gw}}}{32} )^{1/3}
\,.
\end{align}

With these two expressions at hand, we can impose \(P = -  \dot{E}\), which we can write in the form \(\dot{\omega} _{\text{gw}} \propto \omega^{n}\) for some \(n\): since \(\dot{E}\propto \omega _{\text{gw}}^{-1/3} \dot{\omega} _{\text{gw}}\), \(n\) will be \(11/3\), and the specific expression will look like 
%
\begin{align}
\dot{\omega} _{\text{gw}} = \frac{12}{5} \sqrt[3]{2} \qty( \frac{G \mathcal{M}_c}{c^3})^{5/3} \omega _{\text{gw}}^{11/3}
\,.
\end{align}

This equation is in the form \(\omega^{-11/3} \dd{\omega } = K \dd{t}\); integrating from a generic point 0 to point 1 we find \(3K(t_1 - t_0 ) / 8 = \omega_0^{-8/3} - \omega_1^{-8/3}\); if we treat this as an initial value problem we can see that as \(t_1 \) increases there is only a finite ``budget'' on the right-hand side: when \(3K (t_1 - t_0 ) / 8 = \omega_0^{-8/3}\), \(\omega_1^{-8/3}\) must go to 0 so \(\omega_1 \) must diverge. 
The divergence itself is unphysical since, besides corresponding to a breakdown of some of our approximations, it comes about when considering point masses, while compact objects have a finite size. 

Nevertheless, the moment of divergence happens close enough to the actual merger of the objects, therefore it is useful to call it \(t_c\) and to define a time coordinate as \(\tau = t_c - t\).
In terms of this, the solution to the equation reads 
%
\begin{align} \label{eq:gw-frequency-0PN}
f _{\text{gw}} (t) = \frac{\omega _{\text{gw}} (t)}{2 \pi } = \frac{1}{2 \pi }\qty( \frac{ 3 K \tau }{8})^{-3/8} = \frac{1}{\pi } \qty(\frac{ 5}{256 \tau })^{3/8} \qty(\frac{G \mathcal{M}_c}{c^3})^{-5/8}
\,.
\end{align}

% [FIND CITATION FOR THIS STATEMENT]

This expression for \(f _{\text{gw}}\) can be substituted into the gravitational waveforms \eqref{eq:binary-waveform-1}; we must also update the phase term, since \(2 \Omega t\) is the phase for a uniformly circular orbit: we will want to use integrate the angular velocity, to find 
%
\begin{align} \label{eq:phase-quadrupole-emission}
\Phi (t) &= \int^{t} \omega _{\text{gw}}(\widetilde{t}) \dd{\widetilde{t}} = 2 \int^{t} \Omega (\widetilde{t}) \dd{\widetilde{t}}  \\
&= -2 \qty(\frac{5 G \mathcal{M}_c}{c^3})^{-5/8} \tau^{-5/8} + \const
\,.
\end{align}

In terms of this, the amplitude in the two polarizations will read \cite[eqs.\ 4.31--32]{maggioreGravitationalWavesVolume2007}
%
\begin{align} \label{eq:amplitude-quadrupole-emission}
h_{+} (t) &= \frac{1}{r} \qty(\frac{G \mathcal{M}_c}{c^2})^{5/4} \qty( \frac{5}{c \tau })^{1/4} \qty(\frac{1 + \cos^2\iota }{2}) \cos \Phi (t) \\
h_{ \times } (t) &= \frac{1}{r} \qty(\frac{G \mathcal{M}_c}{c^2})^{5/4} \qty( \frac{5}{c \tau })^{1/4} \cos \iota  \sin \Phi (t) 
\,.
\end{align}

As we will discuss in section \ref{sec:data-analysis}, for data analysis it is convenient to have expressions for the Fourier transforms of these. An analytic computation of the integrals is intractable, but we can make use of a technique known as \ac{SPA}, which is discussed in detail in appendix \ref{sec:spa}. 
The final expressions for the Fourier-domain waveforms are equations \eqref{eq:spa-waveforms}. 

\paragraph{Waveform duration}

Waveforms become quite long in the time domain as we reach lower initial frequencies: the duration of the waveform for an equal-mass \ac{BNS} with \(M \approx 2.8 M_{\odot}\) is typically \cite[eq.\ 4.21]{maggioreGravitationalWavesVolume2007}
%
\begin{align} \label{eq:waveform-duration}
\text{duration} \approx \SI{3}{min} \qty(\frac{f_0 }{\SI{20}{Hz}})^{-8/3}
\,,
\end{align}
%
which is calculated by inverting equation \eqref{eq:gw-frequency-0PN}. 
This graphically shown in figure \ref{fig:waveform_length}. 

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{figures/waveform_length}
\caption{Duration of time-domain waveforms for a \(M = 2.8 M_{\odot}\) \ac{BNS}. The dashed line shows the output of equation \eqref{eq:waveform-duration}, while the thick line shows the durations one might concretely use, imposing the number of samples in the time domain is an integer power of 2 and at least slightly larger than the typical duration, so as to have a margin.}
\label{fig:waveform_length}
\end{figure}

\subsection{Spherical harmonics decomposition} \label{sec:spherical-harmonics-decomposition}

The waveform we described so far comes from the quadrupole of the mass distribution, but higher-order moments also generate \acp{GW}.
In general, in units where \(G = c = 1\), one can write the waveform as \cite[eq.\ II.6]{ajithDataFormatsNumerical2011}
%
\begin{align}
h_+ + i h_\times = \frac{M}{r} \sum _{l=2}^{\infty } \sum _{m=-\ell}^{\ell} h_{\ell m} (t) {}_{(-2)}Y_{\ell m} (\iota, \varphi )
\,,
\end{align}
%
where the functions \({}_{-2}Y_{\ell m}\) are called \emph{spin-weighted spherical harmonics}, a generalization of the regular spherical harmonics. 
The only assumption in this expression is the \(1/r\) scaling of the amplitude of the waveform. 
The expansion parameters \(h_{\ell m}\) are time-dependent and complex, and the spin-weighted harmonics depend on the orientation of the basis we choose (see \nameref{sec:sky-pos-polar}).

In the case of aligned spins, the harmonics which give the largest contribution are the \((\ell = 2, m = 2)\) and \((\ell = 2, m =-2)\) ones, which are conjugates of each other. 
The algorithm \ac{mb} currently only reconstructs this mode ---
considering more modes will be needed in order to treat the effects of precession, which happens when the spins are not aligned. 


\subsection{Parameters for a \ac{CBC} waveform} \label{sec:cbc-parameters}

The waveform we wrote explicitly depends on: 
\begin{enumerate}
    \item the chirp mass \(\mathcal{M}_c\), defined in \eqref{eq:chirp-mass};
    \item the distance \(r\), which in a more general cosmological context should be replaced by the \emph{luminosity distance} \(D_L\);
    \item the inclination \(\iota \), which is the angle between the observation direction and the total angular momentum of the system.
\end{enumerate}

These are only some of the parameters which must be considered when discussing a \ac{CBC}. We will now discuss the full set of parameters which can be used to fully describe the binary system generating the waveform \cite[eq.\ 21]{breschiTtBajesBayesian2021}. 

\paragraph{Arrival time and initial phase} \label{sec:arrival-time}

The time at which any given waveform arrives at Earth is arbitrary, as is the global phase of the waveform. 
In practice, one will typically analyze the output from a detector in batches, and in each of these the analysis will be performed in Fourier space. 
Therefore, it is relevant to see how the Fourier-domain waveform responds to a time and phase shift: what is the transform of \(f(t-t_0 ) e^{i \varphi_0} \)? It comes out to be 
%
\begin{align}
\int_{\mathbb{R}} f(t-t_0 ) e^{i \varphi_0 } e^{i \omega t} \dd{t}  = e^{i \omega t_0 + i \varphi_0} \underbrace{\int_{\mathbb{R}} f(t-t_0 ) e^{i \omega (t-t_0 )} \dd{(t-t_0 )}}_{\widetilde{f}(\omega )}
\,,
\end{align}
%
so a time shift corresponds to the addition of a linear term to the phase, while the initial phase can be directly moved from the time to the frequency domain. 

\paragraph{Sky position and polarization} \label{sec:sky-pos-polar}

The wave will be coming from a sky position, which we can describe with respect to a given coordinate system through two angles; it is convenient to use right ascension \(\alpha \) and declination \(\delta \). 
Also, the polarization of the gravitational waves can have an arbitrary angle with respect to the observation direction: we denote this angle as \(\psi \). 
% One might wonder whether this parameter will be fully degenerate with the initial phase \(\phi_0\) and thus unmeasurable, but it can in fact be measured if we have a network of detectors whose response functions to either polarization are different. 

In more technical terms, a general waveform arriving our detector will be a superposition of \acsp{GW} in the TT gauge \eqref{eq:TT-gauge-gw} with varying \(\alpha \), \(\delta \), \(\psi \) as well as different frequencies; we can write it as \cite[eq.\ 1.58]{maggioreGravitationalWavesVolume2007}
%
\begin{align} \label{eq:generic-gw}
h_{ab} (t, \vec{x}) &= \sum _{\text{pol} = +, \times }
\int_{- \infty  }^{\infty } \dd{f} \int \dd[2]{\hat{n}} \widetilde{h}_{\text{pol}} (f, \hat{n}) e^{\text{pol}}_{ab}(\hat{n}, \psi ) e^{-2 \pi i f (t - \hat{n}\cdot \vec{x} / c )} 
\,,
\end{align}
%
where \(\hat{n} = \hat{n} (\alpha , \delta )\) is the vector describing the propagation direction of a specific component --- in the context of a \ac{CBC}, the distribution of the \(e^{\text{pol}}_{ab}(\hat{n}, \psi )\) will include a Dirac delta centered on the position of the source in the sky, while this more general expression can be useful, for example, in the context of a \ac{SGWB}. 

The tensors \(e_{ab}\) are basis tensors: in a frame where \(\hat{n}\) and \(\psi \) are chosen such that the \(+\) polarization stretches the \(x\) and \(y\) axes, they read 
%
\begin{align}
e_{ij}^{+} (\hat{n}=\hat{z}, \psi =0) &= u_i u_j - v_i v_j = \left[\begin{array}{ccc}
1 & 0 & 0 \\ 
0 & -1 & 0 \\ 
0 & 0 & 0
\end{array}\right]  \\
e_{ij}^{ \times } (\hat{n}=\hat{z}, \psi = 0) &= u_i v_j + v_i u_j = \left[\begin{array}{ccc}
0 & 1 & 0 \\ 
1 & 0 & 0 \\ 
0 & 0 & 0
\end{array}\right]
\,,
\end{align}
%
where \(u\) and \(v\) are two unit vectors defining the polarization direction; they are always chosen to be orthogonal, so fixing the angle \(\psi \) is enough to determine them both once we give \(\hat{n}\). 

The aforementioned expansion glosses over a technical issue: the three-dimensional Fourier transform of the \ac{TT} gauge waveform is in the form \(h_{ij}(x) \sim \int \dd[3]{k} A_{ij}(k) e^{ikx}\), so in order to write it like we did we need to define 
%
\begin{align}
\frac{f^2}{c^3} A_{ij} (f, \hat{n}) = \sum _{\text{pol}= +, \times }
\widetilde{h}_{\text{pol}} (f, \hat{n}) e^{\text{pol}}_{ij}(\hat{n})
\,,
\end{align}
%
where we reparametrized the wavevector \(\vec{k}\) through frequency \(f\) and direction \(\hat{n}\), and exploited the decomposition \(\dd[3]{k} = k^2 \dd{k} \dd[2]{\hat{n}}\).

\paragraph{Masses and mass ratio}

The waveform to the lowest order we described only depends on the chirp mass \(\mathcal{M}_c\), but at higher order there also appears a dependence on the ratio of the two masses: \(q = m_1 / m_2 \).
It is customary to fix one of the two masses to always be the largest, therefore constraining \(q \lesseqgtr 1\); we choose the convention \(q \geq 1\).

A possible parametrization for the two masses is \((\mathcal{M}_c, q)\), another is \((M, q)\): these are equivalent, but in the following work we will typically use the latter. 
We shall discuss in section \ref{sec:natural-units} that the total mass \(M\) can be interpreted as an extrinsic parameter.

An alternative parametrization for the mass ratio \(q\) is the symmetric mass ratio \(\nu = \mu / M = q / (1 + q)^2\).

% \todo[inline]{Fix!}

% because of scaling property of the waveforms: we conventionally work with respect to the dimensionless frequency \(Mf\) and the dimensionless time \(t / M\) in order to have one less parameter. 
% If need be, we will refer to a ``conventional'' mass of \(M = 2.8 M_{\odot}\), but our results will be easily scalable to any \(M\). 

\paragraph{Spin}

Compact objects can spin, and the spin of each of the two is a vector with three independent components. 
These vectors \(\vec{S}_i\) have units of angular momentum, but they are typically rescaled as 
%
\begin{align}
\vec{\chi}_i = \frac{c\vec{S}_i}{G m_i^2} \in [-1, 1] 
\ \text{in magnitude}
\,.
\end{align}

The constraint of \(\abs{\chi_i} < 1\) can be approached by realistic models of \acsp{BH}, while realistic models of \acsp{NS} are typically constrained to spin less, at the most \(\abs{\chi _i} \lesssim 0.7\) \cite{loSpinParameterUniformly2011}.
This constraint is hard to experimentally verify since one is faced with the degeneracy between the components \(\chi_{z,i}\) aligned with the direction of the angular momentum and the mass ratio \(q\); in the analysis of the merger GW170807 two sets of prior distributions for the spins were used, \(\abs{\chi } < 0.05\) and \(\abs{\chi } < 0.89\), for this reason \cite{abbottGW170817ObservationGravitational2017}. We have theoretical reasons to believe that the low-spins priors might correspond to a more physically meaningful scenario, but the degeneracy means that the high-spin case is not experimentally excluded, so we must still consider it a possibility.

The qualitative effect of spin is due to both spin-orbit and spin-spin interactions. 

In the simplest spin-aligned case, \(\vec{\chi}_i \propto \vec{L} \), the effect is to make the interaction less attractive (when the spins are aligned, \(\vec{\chi}_1 \cdot \vec{\chi}_2 > 0\)) or to make it more attractive in the alternate case. 

The dynamics when the spins are not aligned are significantly more complicated, since the spins precess and give rise to modulations of the amplitude. 
Because of this, often models restrict themselves to the aligned-spin scenario. 

\paragraph{Tidal deformability of neutron stars}

If our compact objects are extended, they might be able to deform. The astrophysically-motivated scenario we think of is that of neutron stars, but the following characterization could also apply to other exotic compact objects. For concreteness' sake, we will refer to \acsp{NS} only.

The effect of tidal deformation on the inspiral is a complicated process, but we can try to capture its most significant part by limiting ourselves to the quadrupole order of the deformation of the star. 
The discussion of this effect is clearest in the Newtonian context, but it can be also formalized in \ac{GR} \cite[section 14.4.1]{maggioreGravitationalWavesVolume2018}.

Tidal effects are described by the tidal tensor \(\mathcal{E}_{ij} = - \partial_{i} \partial_{j} U\), the traceless\footnote{This tidal tensor describes the effect of one star's gravitational field on the other, so its source is not where we compute it, which is a convoluted way of saying that it should be taken to be a solution of \(\nabla^2 U = 4 \pi \rho \) in vacuum: therefore, \(\nabla^2 U = - \Tr[\mathcal{E}_{ij}] = 0\).} Hessian of the Newtonian potential \(U\). In the weak-field relativistic case, this corresponds to part of the Riemann tensor: \(\mathcal{E}_{ij} = c^2R_{0i0j}\). 

We can describe the effects on the deformed star of such a tidal stress by looking at its quadrupole moment \(Q_{ij}\) (see equation \eqref{eq:quadrupole}).
To linear order and neglecting any time dependence, we will have the relation 
%
\begin{align}
\mathcal{E}_{ij} = - \lambda Q_{ij}
\,.
\end{align}

% \todo[inline]{find better explanation for minus sign here and in def of tidal tensor}

This parameter \(\lambda \) describes the deformability of the star; if it is smaller the star deforms less in response to tidal perturbations. 
In practice the parameter used is not \(\lambda \) itself but one of two common ways to rescale it: the \(\ell=2\) (quadrupole) \textbf{Love number} 
%
\begin{align}
k_2 = \frac{3}{2} \frac{G \lambda }{R^{5}}
\,,
\end{align}
%
where \(R\) is the radius of the deformed \ac{NS}, or the \textbf{tidal deformability} 
%
\begin{align}
\Lambda = \frac{2}{3} k_2 \qty(\frac{Rc^2}{Gm})^{5} 
\,,
\end{align}
%
where \(m\) is the mass of the deformed \ac{NS}. 
The value of these parameters depends on the specific equation of state used in the model; \(k_2\) is typically of the order of \(10^{-1}\), and in the expression for \(\Lambda \) we have a fifth power of the \emph{compactness} \(\sigma = R c^2 / Gm\) of the \ac{NS} --- this is expected to be a small number, but larger than 3,\footnote{A limit on the maximum redshift of radiation from the surface of a \ac{NS} was calculated by \textcite{lindblomLimitsGravitationalRedshift1984} under the assumptions of causality and stability for the nuclear matter, which is equivalent to a compactness limit of \(\sigma \geq 2.83\) \cite{lattimerNeutronStarObservations2007}. } so its fifth power will be of order \(10^{3 \divisionsymbol 4}\). This means that the deformability \(\Lambda \) will typically be of the order \(10^{2 \divisionsymbol 3}\). 

The Love number is useful since it is an expansion parameter for the gravitational field of the deformed \ac{NS}. This field has contributions from both its own quadrupole moment, which is due to the tidal deformation from the other star, and from the gravitational field of the other star itself, which we can expand in terms of the tidal field around the center of the deformed star: \(U _{\text{ext}} \approx - \mathcal{E}_{ij} x_{i} x_{j} / 2\). 

The gravitational field of the deformed star also changes under the effect of the deformation: including the first term in its expansion, which depends on the quadrupole moment, the potential reads  
%
\begin{align}
U _{\text{int}} \approx \frac{Gm}{r} + \frac{3G}{2r^3} \frac{x_i}{r} \frac{x_j}{r} Q_{ij}
\,,
\end{align}
%
where \(r = \abs{x}\) is the radius from the center of the deformed star.

We can then see that under the assumption of linear dependence of the quadrupole on the tidal tensor the two potentials can be added (since we are still in the realm of linear theory):\footnote{A technical fact to remember here is that the expansions do not naturally match: the expansion of the internal potential is in orders of \(1/r\), while the expansion of the external one is in orders of \(r\). } 
%
\begin{align}
U \approx \frac{Gm}{r} - \frac{1}{2} \mathcal{E}_{ij} x_i x_j \qty[1 + 2 k_2 (R / r)^{5}]
\,.
\end{align}

This is the starting point for the relativistic generalization of the result as well, where \(k_2 \) is an expansion parameter for a metric component. 

The meaning of \(\Lambda \) is less immediate ---  the first correction to the phasing of the waveform which appears is\footnote{The meaning of the \ac{PN} expansion will be discussed in section \ref{sec:post-newtonian} --- for now, one can think of it simply as an expansion in orders of \(v/c\).} \cites[eq.\ 14.231]{maggioreGravitationalWavesVolume2018}{flanaganConstrainingNeutronStar2008}
%
\begin{align}
\Delta \Psi^{\text{tidal}}_{\text{5PN}} &= - \frac{117}{256} \frac{m^2}{m_1 m_2 } \widetilde{\Lambda } \qty(\frac{v}{c})^{5} 
\\
\widetilde{\Lambda} &= \frac{16}{13} \frac{(m_1 + 12m_2 ) m_1^{4} \Lambda_1 + (m_2 + 12 m_1 ) m_2^{4} \Lambda_2 }{(m_1 +m_2 )^{5}}
\,.
\end{align}

The parameter \(\widetilde{\Lambda}\), which depends on the tidal deformabilities of the two stars \(\Lambda_{1, 2}\), is called the \emph{reduced tidal parameter}. 

One would expect to see \(\Lambda = 0\) for black holes, and this is true in the nonspinning case; on the other hand, Kerr black holes can exhibit small but nonvanishing deformability. \textcite{letiecSpinningBlackHoles2021} recently showed that, for example, \acsp{BH} with dimensionless spins of the order \(\chi \sim 0.1\) can exhibit nonzero Love numbers on the order of \(k_\ell \sim \num{2e-3}\), around two orders of magnitude less than predicted \ac{NS} values. 
The effect this will have on \ac{GW} emission is yet to be determined, but one can suspect it will be small.

\paragraph{Eccentricity}

A general binary system will orbit in an ellipse with eccentricity \(e \in [0, 1)\); the two semiaxes of the ellipse read \cite[eqs.\ 4.51]{maggioreGravitationalWavesVolume2007}
%
\begin{align}
a = \frac{R}{1- e^2} \qquad \text{and} \qquad
b = \frac{R}{\sqrt{1 - e^2}}
\,.
\end{align}

It can be shown that, for a Keplerian orbit, the semimajor axis \(a\) and the eccentricity \(e\) depend on the total energy \(E\) and angular momentum \(L\) as \cite[eqs.\ 4.50, 4.53]{maggioreGravitationalWavesVolume2007}
%
\begin{align}
e = \sqrt{1 + \frac{2 EL^2}{G^2 m^2 \mu^3}} 
\qquad \text{and} \qquad
a = \frac{Gm \mu }{2 \abs{E}}
\,.
\end{align}

In order to fully describe the \ac{GW} emission from a binary system we must then also account for eccentricity; this parameter can also change as time progresses, and in order to describe this process we need a second evolution equation.
This can be found thanks to the quadrupole angular momentum emission formula, which is analogous to the energy emission one \eqref{eq:energy-emission-quadrupole} \cite[eq.\ 3.99]{maggioreGravitationalWavesVolume2007}:\footnote{The angular momentum emitted in this expression is considered to be both spin and orbital angular momentum.} 
%
\begin{align}
\dv{L^{i}}{t} = - \frac{2G}{5c^{5}} \epsilon^{ikl} \expval{ \ddot{M}_{ka} \dot{\ddot{M}}_{la}} 
\,.
\end{align}

This allows us to make a system of two equations, \(\dv*{E}{t}\) and \(\dv*{L}{t}\), which we can reparametrize as equations for \(\dot{a}\) and \(\dot{e}\) \cite[eqs.\ 4.116--17]{maggioreGravitationalWavesVolume2007}: 
%
\begin{align}
\dot{a} &= - \frac{64}{5} \frac{G^3 \mu m^2}{c^{5} a^3}
\frac{1}{(1-e^2)^{7/2}} \qty(1 + \frac{73}{24} e^2 + \frac{37}{96}e^{4})  \\
\dot{e} &= - \frac{304}{15}  \frac{G^3 \mu m^2}{c^{5} a^4} 
\frac{e}{(1-e^2)^{5/2}} \qty(1 + \frac{121}{304} e^2)
\,,
\end{align}
%
which can be (nontrivially) analytically solved, yielding the result shown in figure \ref{fig:eccentricity}. 

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{figures/eccentricity}
\caption{We show the behaviour of the analytic solution for the semimajor axis \(a(e)\) \cite[eq.\ 4.126]{maggioreGravitationalWavesVolume2007}; the \(x\) axis is on a logit scale, meaning that it is proportional to \(\log (e / (1-e))\). The quantity on the \(y\) axis is not \(a(e)\), but \(a\) (which can have any value) varies proportionally to it: ratios in the form \(a(e_1) / a(e_2)\) are correctly represented in this graph.}
\label{fig:eccentricity}
\end{figure}

It can be clearly seen that eccentricity will decrease as the semimajor axis shrinks due to \ac{GW} emission.
Typical astrophysical binaries need to shrink by several orders of magnitude before merging --- the notorious pulsar in a binary system detected by \textcite{hulseDiscoveryPulsarBinary1975} has a semimajor axis of \(a \approx \SI{2e9}{m}\) and an eccentricity of \(e \approx 0.617\), while the frequency of the \acsp{GW} it emits is \(f _{\text{gw}} = 2 / P \approx \SI{7e-5}{Hz}\) \cite{taylorNewTestGeneral1982}. 

If we were to wait until this reached a frequency range where next generation ground-based detectors might hope to detect it, \(f \sim \SI{10}{Hz}\), we would expect to see (using Kepler's third law \(a^3 f^2 = \const\)) a reduction of semimajor axis by a factor \(\sim 2700\): it would go off-scale to the left in figure \ref{fig:eccentricity}, and we would expect to basically have \(e \approx 0\). 
One can then see that this result holds for all but the most extreme initial values of \(e\). 

This is the reason why eccentricity is often not considered in \ac{GW} modelling, while it is of crucial importance in astrophysical population studies, since it has a large effect on the emitted power (enhancing it) in the early stages of the inspiral.

Eccentric binaries are by no means excluded by this line of argument; there are astrophysical contexts in which they might be generated with high eccentricities combined with already small radii, which would allow \(e > 0\) to be detectable even in the \ac{LIGO}-Virgo band.
Eccentric binary \ac{GW} models do exist \cite{favataConstrainingOrbitalEccentricity2021}, although they do not reach the accuracy of circular ones, and ignoring eccentricities may lead to bias in parameter estimation.\footnote{A good resource on these, based on a paper by \textcite{favataGravitationalwaveMemoryEccentric2011}, is the ``sounds of spacetime'' website \href{Sounds of Spacetime}{https://www.soundsofspacetime.org/elliptical-binaries.html}, which also provides audio renditions of eccentric waveforms (at 1\ac{PN} order).}

\paragraph{Summary}

The parameter vector \(\vec{\theta}\) describing a binary system can be divided into internal and external parameters as 
%
\begin{align}
\vec{\theta} = (\underbrace{q, \vec{\chi}_1, \vec{\chi}_2, \Lambda_1, \Lambda_2,}_{\theta _{\text{int}}} \underbrace{M, D_L, \iota, \alpha, \delta, \psi, t_0, \phi_0 }_{\theta _{\text{ext}}})
\,,
\end{align}
%
where the dependence of the waveform on the external parameters is well-understood and easy to analytically calculate, while the dependence on the internal parameters is complicated.

The main task of the model developed in this work is to reconstruct the complex, nonlinear dependence of the waveform on the \emph{intrinsic parameters} \(q\), \(\Lambda_1\), \(\Lambda_2 \) and the aligned-spin components \(\chi_{1,z} \) and \(\chi_{2, z}\).

\subsection{Natural units and simplifications} \label{sec:natural-units}

In the absence of matter, \ac{GR} is scale invariant: if we consider a \ac{BBH} system with total mass \(M\) and radial separation \(r\),
and we map \(M \to \alpha M\) and \(r \to \alpha r\) for some positive \(\alpha \), as well as rescaling the time \(t \to \alpha t \) and the frequency \(f \to f / \alpha \), the \ac{GW} amplitude \(h\) is preserved. 
% This is consistent with a time rescaling of  as can be seen in equation \eqref{eq:amplitude-quadrupole-emission}, and with a rescaling of the frequency \(f \to f / \alpha \), as can be seen in equation \eqref{eq:spa-waveforms}. 
The fact that this result holds at the quadrupole order can be clearly seen in equation \ref{eq:spa-waveforms}.

This line of reasoning is exact in vacuum GR, and thus for \ac{BBH}; matter is not scale-invariant, so it does not precisely work for \ac{BNS}. 
However, the effects of the \acp{NS} not being point masses are included into the dimensionless tidal parameters \(\Lambda_i \sim k_2 (R/m_i)^{5}\), which depend on the Love number and the compactness of \acp{NS}. If \(k_2 \) and the compactness were constant as the mass varied, this would be scale-invariant. 
It could be the case that the Love number varies with the mass, but this does not affect the validity of the waveforms: it just means that, as we vary \(M\) during parameter estimation, we will be estimating the compactness and \ac{EoS} of \acp{NS} with different masses. 

We can then work in \emph{mass-rescaled natural units}, commonly shortened to just ``natural units'', expressing frequencies as \(Mf\) and times as \(t / M\). This allows us to reduce the dimensionality of the parameter space by one. 

We must be careful, however: the time-domain strain \(h(t)\) is dimensionless, but its Fourier transform \(\widetilde{h}(f)\) has the dimensions of a time, or a mass.

Let us rewrite the \ac{SPA}, 0PN expression for the amplitude (the absolute value of equation \ref{eq:spa-waveforms} for \(\iota = 0\)) to illustrate this point: 
%
\begin{align}
\frac{\abs{\widetilde{h}_+ (f)}}{M_s} = \frac{1}{\pi^{2/3}} \sqrt{ \frac{5}{24}}
(M_s f)^{-7/6} \frac{M_m}{r} \sqrt{\nu }
\,,
\end{align}
%
where we use employ the relation \(\mathcal{M}_c = M \nu^{3/5}\) \eqref{eq:chirp-mass}, as well as \emph{almost} using natural units: \(M_m\) and \(M_s\) denote the values of the total mass as expressed in terms of length (meters) or time (seconds), respectively \(M_m = GM / c^2\) and \(M_s = GM / c^3\).

Conventionally (as well as in \ac{mb}), the waveforms expressed in ``natural units'' are provided as 
%
\begin{align}
\widetilde{h}_{NU} (fM) = \frac{\widetilde{h}(f)}{M_s} \frac{r}{\nu M_m} \overset{\text{0PN}}{\sim} \frac{1}{\pi^{2/3}} \sqrt{ \frac{5}{24}} (Mf)^{-7/6} \frac{1}{\sqrt{ \nu }}
\,.
\end{align}

The amplitude of these is  \(\nu \)-dependent even in the Newtonian limit --- the division by \(\nu \) is convenient in the context of \ac{EOB} calculations. 

When reconstructing a waveform, \ac{mb} will first compute \(\widetilde{h}_{NU} (fM)\), and then the \ac{SI} version as 
%
\begin{align}
\widetilde{h}(f) 
= \widetilde{h}_{NU} (fM) \frac{\mathtt{M}^2}{\mathtt{r}} \nu 
\underbrace{\qty(\frac{G M_{\odot}}{c^3}) 
\qty(\frac{G M_{\odot}}{ c^2 \SI{}{Mpc} })}_{\approx \SI{2.36e-25}{s}}
\,,
\end{align}
%
where \(\mathtt{M}\) is the numeric value of the total mass, expressed in solar masses \(M_{\odot}\), and \(\mathtt{r}\) is the numeric value of the distance, expressed in \SI{}{Mpc}. 

Restricting ourselves to the \((\ell=2, m=2)\) mode (as defined in section \ref{sec:spherical-harmonics-decomposition}) is equivalent to writing the Fourier-domain waveform as 
%
\begin{align}
\widetilde{h}_{+}(f) &= \frac{1 + \cos^2 \iota }{2} \ \widetilde{h} (f)  \\
\widetilde{h}_{ \times } (f) &= \cos \iota \ \widetilde{h}(f)
\,.
\end{align}

\section{Interferometers and data analysis} \label{sec:data-analysis}

Having seen how a gravitational waveform from a \ac{CBC} might look to lowest order, we move to a discussion of the detection of these waveforms with interferometric techniques. 

The response of any detector to a \ac{GW} is a\footnote{Current interferometric detectors have a single scalar response because of their Michelson-Morley design with arms at \SI{90}{\degree}; planned detector such as the Einstein Telescope will exhibit multiple scalar inputs \cite[section 5.3.2]{etscienceteamEinsteinGravitationalWave2011}. The following analysis still applies, each scalar input can be treated analogously; having multiple (from one multi-output detector or from a network) is incredibly beneficial for the accuracy of measurements.} scalar output, which will be in the form 
%
\begin{align}
h(t) = D_{ij} h_{ij}
\,,
\end{align}
%
where \(D_{ij}\) is known as the \emph{detector tensor}. 
We want to apply this expression to the generic one for a gravitational wave \eqref{eq:generic-gw}, which we can simplify by
\begin{enumerate}
    \item removing the integral in \(\dd[2]{\hat{n}}\): in the case of a \ac{CBC} this is an excellent approximation;
    \item removing the dependence on \(\vec{x}\): this is called the \emph{short-arm} approximation, which is warranted by the fact that our detectors have arms with lengths \(L \sim \SI{3}{km}\) and are most sensitive for \ac{GW} frequencies of \(f \sim \SI{100}{Hz}\), while the frequencies corresponding to \(L\) are \(f \sim
     \SI{100}{kHz}\).\footnote{It is possible to treat the problem without this approximation, and in fact it is advisable to: modern interferometers use power recycling techniques, which allow for the effective length of the arms to be much longer than their physical one. In fact, the optimal detection strategy for any given \ac{GW} frequency is to have a detector whose arms are a quarter of the \ac{GW} wavelength long \cite[eq.\ 9.33]{maggioreGravitationalWavesVolume2007} --- this balances the effect of the deformation due to the \ac{GW} changing sign during the time of flight of any specific photon with the ``stacking'' effect of the photon taking a longer path through the deformed space. A proper discussion of these aspects, however, is beyond the scope of this work.}
\end{enumerate}

This leads to the following expression for the observed signal:
%
\begin{align}
h(t) &= \sum _{\text{pol}= +, \times } \underbrace{D^{ij} e_{ij}(\hat{n}, \psi )}_{F _{\text{pol}}}  \underbrace{\int_{- \infty }^{\infty } \dd{f} \widetilde{h} _{\text{pol}} e^{-2 \pi i f t}}_{h _{\text{pol}}(t)}  \\
&= F_+ h_+ (t) + F_\times h_\times (t)
\,.
\end{align}

The \emph{detector pattern functions} \(F_{+, \times }\) can be computed explicitly; for a Michelson-Morley interferometer they read 
%
\begin{align}
F_{+} &= \frac{1}{2} \qty(1 + \cos^2 \theta ) \cos 2 \phi \cos 2 \psi - \cos \theta \sin 2 \phi \sin 2 \psi   \\
F_{ \times } &= \frac{1}{2} \qty(1 + \cos^2 \theta ) \cos 2 \phi \sin 2 \psi + \cos \theta \sin 2 \phi \cos 2 \psi  
\,,
\end{align}
%
where \(\theta \), \(\phi \) are the two angles describing the direction the \ac{GW} is coming from in a frame aligned with the axes of the detector --- they will depend on the sky position of the source (\(\alpha \), \(\delta \)) as well as the orientation of the detector in space (which depends on well-known parameters such as its latitude, the orientation of the earth at each time and so on).

\subsection{Matched filtering}

We have seen how the \ac{GW} signal will look to our detector: \(h(t)\), but in practical experiments what we will measure will be in the form \(s(t) = h(t) + n(t)\),\footnote{The ``noise'' described here is not actually what is measured: the output of the detector is not \(h(t)\) but it is a linear function of it --- even without accounting for the technical details of the measurement, the quantity measured is the intensity of the light at the dark fringe of the detector, not directly \(h\). Nevertheless, if we know the transfer function of the detector we can refer the measured noise to an ``effective noise'' \(n(t)\), which would be the noise we would need to add to \(h(t)\) in order to see the signal we see. This effective noise is what we will call \(n\) hereafter.} and typically the magnitude of the noise timeseries \(n(t)\) will be much larger than the magnitude of the signal. 

This poses an issue both for the detection of a signal and for the analysis of a signal which has been identified as such. 
The technique we will describe here, matched filtering, has applications in both branches of \ac{GW} data analysis.

The idea is to define a \emph{filter}, a  map from the signal timeseries to \(\mathbb{R}\), in such a way that its value is low if there is no signal, and it is high if there is a signal of a certain shape. 
A common choice because of its computational simplicity is a \emph{linear} filter, written as 
%
\begin{align}
s(t) \to \hat{s} = \int \dd{t} s(t) K(t)
\,
\end{align}
%
for some filter function \(K(t)\), which we can select arbitrarily.
How can we determine the best choice of \(K\)?
We want to maximize the \emph{distinguishability} between true signals and random noise, which we can quantify through the \ac{SNR}:\footnote{Properly speaking, this quantifies the distinguishability only under the assumption of zero-mean noise, otherwise we could make it arbitrarily large by adding a constant to \(s(t)\).}
%
\begin{align}
\text{SNR} = \frac{\mathbb{E}(\hat{s} | \text{presence of \(h\)}) }{\sqrt{\var{\hat{s} | \text{absence of \(h\)}}}} = \frac{S}{N}
\,,
\end{align}
%
where we compute the root of a variance for \(N\) since if there is only noise we expect \(\hat{s} = \int \dd{t} n(t) K(t)\) to be a random variable.

In order to properly express this, let us discuss our assumptions about the statistical properties of the noise: the simplest noise we can characterize is 
\begin{enumerate}
    \item stationary: its statistical properties are unchanging in time. This is not true in real detectors, but if the variation is slow enough one can work with ``local'' properties, on the scale of hours or days.
    \item zero-mean: \(\expval{n(t)} =0\); this can be enforced by subtracting an offset.
    \item uncorrelated in Fourier space: this can be stated simultaneously with the definition of the variance of each Fourier component, which is expressed through the single sided \textbf{\ac{PSD}}\footnote{The distinction between the single- and double-sided \ac{PSD} depends on whether we want to use negative frequencies in the integral to recover the variance at each time or not: 
    %
    \begin{align}
    \expval{n^2(t)} 
    = \int_{0}^{\infty } \dd{f} S_n^{\text{single-sided}}(f)
    = \int_{-\infty }^{\infty } \dd{f} S_n^{\text{double-sided}}(f)
    \,.
    \end{align}
    
    Since the noise is real-valued, these two are simply related by \(S_n^{\text{single-sided}} = S_n^{\text{double-sided}}/2\).
    } \(\expval{\widetilde{n}^{*}(f ) n(f )} = \delta (f - f' ) S_n(f ) / 2\). 
    \item Gaussian: each Fourier component is normally distributed around zero, with a variance described by the \ac{PSD}.
\end{enumerate}

The \ac{PSD}, as defined, has the dimension of an inverse frequency; since it describes a variance it is often useful to discuss its square root, the \emph{spectral strain sensitivity}, or \emph{amplitude spectral density} \(\sqrt{S_n}\), with dimensions \(1/ \sqrt{ \SI{}{Hz}}\). 

With these assumptions, we can write the \ac{SNR}, moving to Fourier space, as \cite[eq.\ 7.45]{maggioreGravitationalWavesVolume2007}
%
\begin{align} \label{eq:snr}
\frac{S}{N} = \frac{\int_{\mathbb{R}} \dd{f} \widetilde{h}(f) \widetilde{K}^{*}(f) }{\sqrt{\int_{\mathbb{R}} \dd{f} (S_n(f) / 2) \abs{\widetilde{K}(f)}^2}} = \frac{(u|h)}{\sqrt{(u|u)}}
\,,
\end{align}
%
where we defined the \textbf{Wiener product} between two real-valued signals \(a\) and \(b\) as the Fourier-space expression \cites{finnDetectionMeasurementGravitational1992}[eq.\ 7.46]{maggioreGravitationalWavesVolume2007}
%
\begin{align}
(a | b) = 4 \Re \int_{0}^{\infty } \dd{f} \frac{ \widetilde{a}^{*} (f) b(f)}{S_n(f)}
\,.
\end{align}

The reason for the presence of the real part is that we want this to match the previous expression, where we know the signal \(S\) to be real-valued; the factor 4 is a combination of the factor of \(2\) in the definition of the \ac{PSD} and the fact that we restrict the integral to positive frequencies only, using the fact that the negative-frequency part gives the same contribution for real-valued signals.

We also defined the modified filter \(u\), which is defined so that its Fourier transform reads \(\widetilde{u}(f) = \widetilde{K}(f) S_n(f) / 2\), which allows the expression with the Wiener product to match the previous one.

This expression can then be written as \(S/N = (\hat{u} | h)\), where \(\hat{u} = u / \sqrt{(u|u)}\) This is then maximized by \(\hat{u}\) parallel to \(h\) with respect to the metric defined by the Wiener product: \(\hat{u} \propto h\) means that 
%
\begin{align}
\widetilde{K}(f) \propto \frac{\widetilde{h}(f)}{S_n(f)}
\,.
\end{align}

In other words, the best way to find a signal buried in noise is to scale the Fourier-domain expression for the filter by the noise \ac{PSD}. 

\paragraph{Whitening}

An alternative way to write the same expression is through the concept of \emph{whitening}: if \(S_n(f)\) is known, we can transform any signal \(a(t)\) into 
%
\begin{align}
a_w(t) \qquad \text{such that} \qquad \widetilde{a}_w (f) = \frac{\widetilde{a}(f)}{\sqrt{S_n(f) / 2}}
\,.
\end{align}

In other words, we are mapping a signal into another signal where all the noise Fourier components are uniformly scaled: white noise. 

In terms of the whitened signals, the Wiener product just reads 
%
\begin{align}
(a|b) = 2 \Re \int_{0}^{\infty } \dd{f} \widetilde{a}_w^{*} (f) \widetilde{b}_w(f) 
\,.
\end{align}

\paragraph{Optimal \ac{SNR}}

The expression for the \ac{SNR}, if we are using the optimal filter, is then (in terms of an arbitrary constant \(C\)):
%
\begin{align}
\text{optimal \ac{SNR}} = \frac{(Ch | h)}{\sqrt{(Ch|Ch)}} = \sqrt{(h|h)} 
= 4 \int_{0}^{\infty } \dd{f} \frac{\abs{\widetilde{h}(f)}^2}{S_n(f)}
\,.
\end{align}

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{figures/characteristic_strains}
\caption{We show several comparable quantities: the characteristic noise strains corresponding to the estimated 
\acp{PSD} of \ac{aLIGO} and \ac{ET}, the ones corresponding to the actual \acp{PSD} in the three detectors at the time of the detection of GW170817, and the characteristic signal strain corresponding to a theoretical waveform calculated with GW170817 best-fit parameters. 
% Comparing this single waveform to three different detectors' \acp{PSD} is not completely warranted, since their different locations and orientations give rise to different detector patterns.
The waveform shown is lowered by a factor \(8\) compared to the value it would have with perfect detector orientation and zero inclination. 
}
\label{fig:characteristic_strains}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{figures/integrating_SNR}
\caption{Integrand in the calculation of the optimal \ac{SNR} for a GW170817-like signal with the three detectors of the \ac{LIGO}-Virgo collaboration. The plotted data corresponds to figure \ref{fig:characteristic_strains}: we show the square ratio of \(h_c\) to the three actual \acp{PSD}. The units for the two axes are such that the area below one of these curves is exactly equal to the observed \ac{SNR}.}
\label{fig:integrating_SNR}
\end{figure}

Amplitude strain profiles, as well as Fourier transforms of signals, are often plotted with log-scales: in order to have an intuition for this quantity we can reframe it as 
%
\begin{align}
\text{optimal \ac{SNR}} &=
\int_{- \infty }^{\infty } \dd{\log f}  \frac{h_c^2 (f)}{h_n^2(f)}  
\marginnote{Used \(\dd{\log f} = \dd{f} / f\).}\\
h_c (f) &= 2 f \abs{\widetilde{h}(f)}  \\
h_n (f) &= \sqrt{f S_n(f)}
\,,
\end{align}
%
where the quantities \(h_c\) and \(h_n\) are called the \textbf{characteristic strains} of signal and noise \cite[eqs.\ 17--19]{mooreGravitationalwaveSensitivityCurves2015}. 
They are both dimensionless, the way this integral is expressed allows us to integrate ``by eye'': if we plot log-characteristic strain against log-frequency, the positive area between \(h_c\) and \(h_n\) will be proportional to the optimal \ac{SNR}. 

This is shown in figure \ref{fig:characteristic_strains}, with specific reference to the event GW170817. We both show the \acp{PSD} computed from the data near the actual event and the two design sensitivities for the current-generation \ac{aLIGO} and the planned, third generation detector \ac{ET}. 
The optimal \ac{SNR} for a signal with the parameters of GW170817, navely computed, is much larger than the actual value of the measured \ac{SNR}. This is due to the inclination of the source, its position in the sky and the specific realization of the experimental noise. 
These all act to decrease the experimental \ac{SNR}, and they also differ among the various detectors for each signal, since they are differently oriented. 

These effects can be analytically accounted for in the analysis of a signal; in the making of figure \ref{fig:characteristic_strains} we simply divide the signal characteristic strain by a constant, selected in order to match the measured \ac{SNR}. 
The value 8 is chosen for the constant so that the Livingston \ac{SNR} of \(\sim 26.4\) is matched by the graph; the Hanford \ac{SNR} was \(\sim 18.8\) while this graph shows \(\sim 10\); the Virgo \ac{SNR} of \(\sim 2\) is matched by the graph \cite{abbottGW170817ObservationGravitational2017}.

The fact that integrating \((h_c / h_n)^2\) yields the \ac{SNR} is represented in more detail in figure \ref{fig:integrating_SNR}, a plot of \((h_c / h_n)^2\) against log-frequency.

Alternatively, we can define an ``amplitude signal strain spectral density'': 
%
\begin{align}
\sqrt{S_h (f)} = 2 \sqrt{f} \abs{\widetilde{h}(f)}
\,,
\end{align}
%
which is comparable to \(\sqrt{S_n(f)}\), in the sense that it also has units of \SI{}{Hz^{-1/2}}.

\paragraph{The (optimal) mismatch}

The scalar product \((a|b)\) between waveforms allows us to define a distance between them which is meaningful in terms of their distinguishability in data analysis.
Specifically, we use the fact that in any inner product space we can write the product as \((a|b) = \sqrt{(a|a) (b|b)} \cos \theta \), where \(\theta \) can be interpreted as an angle between \(a\) and \(b\). 
Therefore, we can define the \emph{fidelity}, or \emph{mismatch}\footnote{Here we choose to define the fidelity as a synonym for the mismatch, but some authors instead use \(\text{fidelity} = 1 - \text{mismatch}\).}``distance'':\footnote{This is not a distance in the mathematical sense: it does not satisfy the identity of indiscernibles principle since \(M(a, Ka) = 0\) for any constant \(K\), and it does not satisfy the triangle inequality \(M(a, b) \leq M(a, c) + M(b, c)\) --- think, for example, of \(a\) and \(c\) at right angles to one another (so \(M(a, c) = 1\)) and \(b\) in the middle, at 45 from either, so \(M(a, b) = M(b, c) = 1 - \sqrt{2} / 2 \approx 0.3\). Then, \(M(a,c) = 1 > M(a, b) + M(b, c) \approx 0.6\), in violation of the inequality. 

This is not a problem for us: this mismatch is still a useful metric even if it is not a distance. }
%
\begin{align}
F(a, b) = 1 - \frac{(a|b)}{\sqrt{(a|a) (b|b)}} = 1 - \cos \theta 
\,.
\end{align}

This mismatch is computed among two waveforms with all of their parameters fixed; in practice, it is often useful to let the initial phase and coalescence time of the waveforms free to vary, and compute the \emph{optimal mismatch}
%
\begin{align}
\mathcal{F}(a, b) = 1 - \max_{\phi_0 , t_0 } \frac{(a|b(\phi_0, t_0 ))}{\sqrt{(a|a)(b|b)}}
\,,
\end{align}
%
where either of the two waveforms is shifted in time and in phase.

In practice, this does not affect the norms of the waveforms in the denominator, but instead it means that the scalar product between \(a = A_a(f) e^{i \phi _a (f)}\) and \(b = A_b (f) e^{i \phi _b (f)}\) reads 
%
\begin{align}
\max_{\phi_0 , t_0 } (a|b(\phi_0 , t_0 )) 
&= \max_{\phi_0, t_0 } 4 \Re \int_{0}^{\infty } \dd{f} \frac{A_a (f) A_b(f) e^{i \phi_a - i \phi _b + 2 \pi i f t_0 + \phi_0 }}{S_n (f)} \\
&= \max_{t_0 } 4 \abs{\int_{0}^{\infty } \dd{f} \frac{A_a (f) A_b(f) e^{i \phi_a - i \phi _b + 2 \pi i f t_0 }}{S_n (f)}}
\,.
\end{align}

This relation also means that while the mismatch \(M(a, b)\) could in principle be as large as \(2\) (for \(a(f) = -b(f)\)) the optimal mismatch is bounded by \(1\), since there will always be a phase choice to make \((a|b)\) positive, albeit small in magnitude.

% This is useful in \ac{GW} analysis since it reduces the dimensionality of the parameter space by 2; we can 

\subsection{Target fidelity} \label{sec:target-fidelity}

We defined the fidelity as a distance induced by the Wiener product, but we have yet to show that it actually measures what we need. 
We shall use it to evaluate the accuracy of our waveform templates against certain reference templates; this needs to satisfy two independent criteria \cite{lindblomModelWaveformAccuracy2008}.

\begin{enumerate}
    \item In a matched-filtering search for signals, they need to be accurate enough that we do not miss a large fraction of the signals --- this is called \emph{effectualness} \cite[]{damourAccuracyEffectualnessClosedform2011};
    \item in the data analysis of a signal, they need to be accurate enough that they do not induce a significant bias in the estimation of parameters --- this is called \emph{accuracy}.
\end{enumerate}

It turns out that fidelity is a useful metric for both of these, but the thresholds we need to set are chosen differently.

\paragraph{Effectualness}

In the matched-filtering context, we search for signals by comparing (with the Wiener product) the measured data against a bank of templates with varying parameters, and checking whether any of them surpass a certain \ac{SNR} threshold.

The ineffectualness of our templates is one factor which makes it more likely for us to miss a signal; another source of error in this regard is given by the grid size of the template bank --- if it is too sparse, the true parameters of the system might lie quite far from any grid point.
Let us neglect the second of these aspects, since it is independent of the template-making efforts of this work, and focus on the first. 

How does a certain template fidelity \(\mathcal{F}\) relate to the fraction of signals we will miss because of the ineffectualness of our templates, supposing that our template bank has a vanishing grid size? 

We already discussed the fact that if the true signal is \(h\), then the optimal \ac{SNR} is \(\text{SNR} = \sqrt{(h|h)} = (s|h) / \sqrt{(h|h)}\); if instead the signal is \(h\) while our template includes \(h'\), the maximum \ac{SNR} we will be able to reach is \(\text{SNR}' = (h|h') / \sqrt{(h'|h')} \approx (1 - \mathcal{F}) \text{SNR}\). 
This also applies in the noisy case: having imprecise templates will lead to a decrease in the effective \ac{SNR}. 

For very loud signals this will not be an issue, but the distribution of the sources we detect is peaked at the edge of detectability; if we make the simplifying assumption that the distribution of sources is uniform in space and the volume scales as the luminosity distance cubed\footnote{This is not true in a cosmological context, i.e.\ at high redshift: the comoving volume scales as \(d_L^3 / (1+z)^3\). For \acp{BNS} detections have only ever been achieved so far with \(z \lesssim 0.05\), meaning that the difference is of the order of \SI{15}{\%}, while for \ac{BBH} the bound is \(z\lesssim 1\), for which the calculation with \(d_L^3\) alone is wrong by almost an order of magnitude. Specifically, the comoving volume is \emph{smaller} than \(\propto d_L^3\), which makes the bound for the ineffectualness of templates more forgiving in the high-redshift context.} we find that the fraction of sources we miss due to template ineffectualness is roughly \(1 - (1-\mathcal{F})^3\) \cites[eq.\ 18]{damourAccuracyEffectualnessClosedform2011}[eq.\ 2.21]{owenSearchTemplatesGravitational1996}.

A commonly used threshold by the \ac{LIGO}-Virgo collaboration is to accept missing \SI{10}{\percent} of the signals, therefore setting \(\mathcal{F}_{\text{max}} \approx 0.035\) \cite[]{lindblomModelWaveformAccuracy2008}.

\paragraph{Accuracy}

The condition needed for data analysis is stricter.
We can quantify the bias given by our waveform in terms of the error in parameter estimation we have from the intrinsic detector noise \cites[sec.\ A]{lindblomModelWaveformAccuracy2008}[sec.\ C]{damourAccuracyEffectualnessClosedform2011}. 
If we allow for the bias due to waveform inaccuracy to be comparable to the one due to intrinsic statistical uncertainty (i.e.\ smaller than \(1 \sigma \)) we find that in the Gaussian approximation, for a signal detected with a certain \ac{SNR} and for which we want to estimate \(D\) intrinsic parameters we will need our inaccuracy to be bounded by
\cites[appendix G]{chatziioannouConstructingGravitationalWaves2017}{gambaWaveformSystematicsGravitationalwave2021}:\footnote{It has been suggested \cite[sec.\ III]{purrerGravitationalWaveformAccuracy2020} that in practical applications this criterion is too strict, and that the biases in parameter estimation it suggests are an overestimate.}
%
\begin{align}
\mathcal{F} \leq \frac{D}{2 \text{SNR}^2}
\,.
\end{align}

As an example, GW170817 was detected with a combined SNR \(\approx 32.4\) \cite[]{abbottGW170817ObservationGravitational2017}, meaning that the fidelity needed to analyze it is \(\mathcal{F} \lesssim \num{2.4e-3}\) if we are considering five intrinsic parameters.

\paragraph{Surrogates}

The previous considerations regard the accuracy of a waveform compared to the true signal; however, \ac{mb} is a surrogate model: it does not model any physics itself, relying instead on a dataset generated with another model. 

This means that the final accuracy which can be reached is bounded by the accuracy of the underlying model, and we must seek not to worsen it by a large margin.

Comparing the \ac{EOB} model currently used in the training of \ac{mb}, \texttt{TEOBResumS}, to numerical relativity simulations we get maximal values for the mismatch of \(\mathcal{F} \simeq \num{2.5e-3}\) \cite[fig.\ 1]{nagarTimedomainEffectiveonebodyGravitational2018}, while the bulk of the distribution lies in the \(\mathcal{F} \sim \num{e-4} \divisionsymbol \num{e-3}\) range.
We shall discuss in section \ref{sec:accuracy} how this compares to the reconstruction errors by \ac{mb}.

\subsection{Parameter inference: studying the signal}

Modern data analysis techniques for \ac{GW} signals must be Bayesian: we need to extract estimates for the parameters generating a signal of which we only have one measurement. 

The main quantity we want to extract from our analysis is the \textbf{posterior probability density function} \(\mathbb{P}(\vec{\theta} | s)\), where \(\vec{\theta}\) is the parameter vector while \(s\) represents the data from the detector. 
If we integrate it in a certain hyper-volume \(\Omega \), we get \(\int_{\Omega } \dd[n]{\vec{\theta}} \mathbb{P}(\vec{\theta} | s)\): the answer to the question ``given the data we measured, what is the probability that the parameters of the system were contained in the region \(\Omega \)?''

The way we write these probabilities is a compactification of notation: 
after the ``given'' symbol we should also always ideally include all the other assumptions about the signal, the noise, and the way they are combined into \(s = h + n\): in the context of \ac{GW} data analysis, this also includes the choice of waveform approximant. 
We will leave this implicit, but we understand that the probabilities calculated will always be model-dependent. 

A Bayesian approach starts by applying Bayes' theorem: 
%
\begin{align}
\underbrace{\mathbb{P}(\vec{\theta}| s )}_{\text{posterior}} = \underbrace{\frac{1}{\mathbb{P}(s)}}_{\text{evidence}} \underbrace{\mathbb{P}(s | \vec{\theta})}_{\text{likelihood}} \underbrace{\mathbb{P}(\vec{\theta})}_{\text{prior}}
\,.
\end{align}
%
% where the reason we can neglect the dependence on \(\mathbb{P}(s)\) is that it is a constant: since probability density functions are normalized to have unit integral over the whole space, we can worry about normalization in the end. 

The normalization factor \(\mathbb{P}(s)\) is called the \emph{evidence}, and it can be expressed as 
%
\begin{align}
\mathbb{P} (s) = \int \mathbb{P}(s | \vec{\theta}) \mathbb{P}(\theta ) \dd[n]{\theta }
\,,
\end{align}
%
since the posterior must be normalized to have unit integral in order to be a probability distribution. 

% Also, there are techniques to explore the posterior probability density space (such as \ac{MH} sampling) which can use an unnormalized version of the posterior.

The prior, which encodes our prior belief about the potential values of the parameters, is often chosen to be uninformative,\footnote{This does not necessarily mean ``uniform'': there is a method, known as Jeffrey's prior, which allows one to maximize the ``ignorance'' about a parameter once a likelihood is given, through what is basically an argument for reparametrization invariance. For example, an uninformative prior on the mean of a Gaussian is uniform, while an uninformative prior on its standard deviation is log-uniform.} so that we do not introduce bias in the analysis. 
In certain cases it might be warranted to use ``biased'' priors: for example, the analysis for GW170817 offers results based on a low-spin and a high-spin prior \cite{abbottGW170817ObservationGravitational2017}: the first is theoretically motivated and might be more meaningful, but the second is still allowed by the data. 

The second ingredient is the likelihood \(\mathbb{P}(s | \vec{\theta})\): this is where signal modelling comes in, since the likelihood needs to include the way the theoretical signal \(h_\theta (t)\) depends on the parameters. 

The posterior distribution \(\mathbb{P}(\vec{\theta} | s)\) contains all the information we can gather about the parameters, and it can be explored without computing the evidence, since certain algorithms (such as \ac{MH}, algorithm \ref{alg:metropolis-hastings}) can explore unnormalized distributions. 

However, this makes the assumption that the model --- which is practically represented by the choice of parameters, likelihood and prior --- is correct; as mentioned before we should really be writing \( \mathbb{P}(s) = \mathbb{P}(s | \text{model})\). 
If one only shows the posterior, the results cannot be directly compared with ones corresponding to a different model. Therefore, the results of a full data analysis should include the posterior as well as the evidence \cites{skillingNestedSamplingGeneral2006}{knuthBayesianEvidenceModel2015}.

Specifically, if we have the evidence for a specific signal corresponding to two models, \(\mathbb{P}(s | M_1 )\) and \(\mathbb{P}(s | M_2 )\), we can compute the \emph{Bayes factor}, which allows us to update our belief about the relative probabilities of the two models 
%
\begin{align}
\underbrace{\frac{\mathbb{P}(M_1 | s)}{\mathbb{P}(M_2 | s)}}_{\text{posterior odds}} = \underbrace{\frac{\mathbb{P}(s | M_1 )}{\mathbb{P}(s | M_2 )}}_{\text{Bayes factor}} \underbrace{\frac{\mathbb{P}(M_1 )}{\mathbb{P}(M_2 )}}_{\text{prior odds}}
\,.
\end{align}

\paragraph{Gravitational wave likelihoods}

What is the probability of observing \(s = h_\theta + n\) if we fix \(\theta \)? The theoretical signal \(h_\theta \) can be computed and is thereafter fixed, likewise \(s\), so this is just the probability of observing a certain realization of the noise: under the assumption of Gaussianity, it will read 
%
\begin{align}
\mathbb{P}(h_\theta + n | \vec{\theta})  
&\propto \exp( - \frac{1}{2} \int_{\infty }^{\infty } \dd{f} \frac{\abs{n(f)}^2}{S_n(f) / 2} )
\\
&\propto 
\exp(- \frac{(n|n)}{2}) 
= \exp( - \frac{(s-h_\theta | s-h_\theta )}{2} )  \\
&\propto \exp(
     (s | h_\theta ) 
     - \frac{(s|s)}{2} 
     - \frac{(h_\theta |h_\theta )}{2}
     )  \\
&\propto \exp( (s | h_\theta ) - 
\frac{(h_\theta | h_\theta )}{2})
\,.
\end{align}

This is a closed-form expression for our posterior probability density, so if we could compute it precisely and efficiently we would be done: the posterior distribution \(\mathbb{P}(\theta | s)\) conceptually includes all the possible information we could extract about the parameters from our observation. 
% This, of course, neglects several issues: the noise in the detector is not really Gaussian as this expression assumes, 

We can use \emph{estimators} for single parameters and their variances in order to better understand what we have measured: these are functions which take the full posterior and return an estimate for a single quantity, such as the value for a specific parameter.
These will always be a simplification of the true distribution, but they are very useful by virtue of being simple to understand.

We ask of these estimators that they be 
\begin{enumerate}
    \item consistent: they should converge to the true value as more data is included;
    \item efficient: they should minimize the variance\footnote{Here it is important to be careful: this is not the variance of the parameter, an estimate of the error we assign to it based on our single experiment, but the variance of the \emph{estimates} taken over the space of possible experimental results we could have gotten while keeping the value of the true parameter fixed to a certain value} of the estimate;
    \item robust: they should not be very sensitive to small fluctuations in the posterior distribution.
\end{enumerate}

A choice which satisfies these criteria quite well is the \textbf{Bayes estimator}, which estimates a parameter \(\theta^{i}\) and the covariance matrix component \(\Sigma_{ij}\) as 
%
\begin{align}
\hat{\theta}^{i} &= \int \dd[n]{\vec{\theta} } \theta^{i}\mathbb{P}(\vec{\theta} | s)  \\
\hat{\Sigma}_{ij} &= \int \dd[n]{\vec{\theta}} 
\qty(\theta^{i}  - \hat{\theta}^{i})
\qty(\theta^{j}  - \hat{\theta}^{j}) 
\mathbb{P}(\vec{\theta} | s)
\,.
\end{align}

Depending on the way the posterior distribution is calculated and parametrized, computing this may be impractical.
Other choices include estimating the parameters by the values which maximize the likelihood or the posterior, and the covariance from the Hessian of the \ac{PDF} around that point. 

\subsection{Posterior sampling}

So, how do we compute the posterior distribution \(\mathbb{P}(\vec{\theta} | s)\) in practice? We know how to evaluate it at a single point \(\vec{\theta}\), so we could evaluate it on some sort of grid, say, sampling \(N\) equally spaced points in a reasonable interval for each parameter.
The curse of dimensionality makes this infeasible: if we have \(n\) parameters we would need \(N^{n}\) evaluations; even with a very small \(N \sim 10\) this quickly becomes unreasonably large, since we typically have \(n \sim 15\) parameters. 

\paragraph{Monte Carlo Markov Chains}

One solution to this issue is to stochastically sample \(\mathbb{P}(\theta | s)\), taking steps in randomly determined directions using a rule which includes information about the probability distribution. 
If the rule is appropriately selected, the sequence of points touched by this random walk will approximate a set of samples for the true distribution. This is known as \textbf{Monte Carlo} sampling. 
A common way to construct an appropriate rule is to make it memory-less, so that each new point is determined only based on the probability distribution and the current point. This is known as a \textbf{Markov Chain}. 

Several algorithms implement \ac{MCMC} sampling; a common choice is the Metropolis-Hastings one, which is shown as algorithm \ref{alg:metropolis-hastings}; the function \(p(\theta )\) should be chosen to be proportional to \(\mathbb{P}(\theta | s)\) (the normalization is irrelevant), and we need to provide a probability density function \(g(\theta _{\text{new}}  | \theta  )\) such that samples from \(g\) can be easily be drawn. A common choice for \(g\) is a Gaussian distribution centered in \(\theta \), which has the advantage of being symmetric: \(g( \theta _{\text{new}}| \theta ) = g (\theta | \theta _{\text{new}})\).
Further, we need a randomly chosen initial point \(\theta_0 \).

\begin{algorithm}
\caption{Metropolis-Hastings algorithm. }\label{alg:metropolis-hastings}
\begin{algorithmic}
\Require $p(\theta )$, \(g(\theta _{\text{new}} | \theta  )\), \(\theta_0 \), \(N _{\text{samples}}\)
\State $i \gets 0$
\State $S \gets \emptyset$ 
\While{$i < N _{\text{samples}}$}
\State \(\theta _{\text{new}} \gets \text{ sample from } g(\theta _{\text{new}} | \theta_{i})\)
\State \(\alpha \gets p(\theta _{\text{new}}) / p(\theta_i) \times g(\theta _i | \theta _{\text{new}}) / g(\theta _{\text{new}} | \theta_i)\) 
\State with probability \(\min(\alpha, 1) \) accept
\If{accept}
    \State $\theta_{i+1} \gets \theta  _{\text{new}}$
\Else
    \State $\theta _{i+1} \gets \theta _i$
\EndIf
\State \(S \gets S \cup \theta_{i+1}\)
\State \(i \gets i+1\)
\EndWhile \\
\Return sample set \(S\). 
\end{algorithmic}
\end{algorithm}

This random walk will eventually (for \(N _{\text{samples}} \to \infty \)) converge to the true distribution; there are several heuristics which can be used to check whether this is actually happening in a specific number of steps, such as measuring the autocorrelation of the chain, or running several chains starting at different points and checking that they ``mix'' appropriately. 

\paragraph{Nested sampling}

This technique allows for the simultaneous calculation of the evidence \(\mathbb{P}(s) = \int \mathbb{P}(s|\theta) \mathbb{P}(\theta ) \dd[n]{\theta }\) as well as the likelihood \cites{skillingNestedSamplingGeneral2006}{siviaDataAnalysisBayesian2006}[app.\ B]{breschiTtBajesBayesian2021}{betancourtNestedSamplingConstrained2011}.

The idea of this algorithm is to define the \emph{prior mass} variable 
%
\begin{align}
X(\lambda ) = \int_{\mathbb{P}(s | \theta) > \lambda } \mathbb{P}(\theta) \dd[n]{\theta }
\,,
\end{align}
%
which quantifies the ``mass'' in parameter space (with the prior distribution as ``density'') of the region in which the likelihood \(\mathbb{P}(s | \theta )\) is larger than \(\lambda \). 

Since the prior must be normalized \(X\) is bounded to lie in \([0, 1]\), and the evidence can be written as 
%
\begin{align}
\mathbb{P}(s) = \int_{0}^{1} \mathbb{P}(s | \theta ) \dd{X}
\,.
\end{align}

If we knew the values of the likelihood at certain points \(X_i\) with corresponding likelihood values \(L_i\), then we could approximate the evidence as 
%
\begin{align}
\mathbb{P}(s) \approx \frac{1}{2} \sum _{i=1}^{N} (X_{i-1} - X_{i+1}) L_i
\,.
\end{align}

The practical problem in the evaluation of this integral in the high-dimensional context of parameter estimation is the fact that the region where the likelihood is high is typically very small in terms of prior mass; this is especially severe in the most desirable scenarios, where we are learning a great deal of new information compared to the non-informative prior, i.e.\ constraining our parameters very well \cite[sec.\ 4]{skillingNestedSamplingGeneral2006}.

Ideally, we'd want to sample with a uniform distribution in \(\log X\); 
the nested sampling method allows us to do so stochastically, with the procedure outlined as algorithm \ref{alg:nested-sampling}. 

The way the points are selected forces them to be distributed close to uniformly in \(\log X\), which means it is a good approximation to just set \(\log X_i = - i / N\) for the samples. 
Alternatively, one could sample the prior distribution to get a more accurate answer. 

\begin{algorithm}
\caption{Nested sampling algorithm. }\label{alg:nested-sampling}
\begin{algorithmic}
\Require set of \(N\) points \(\theta _j\) sampled from the prior, likelihood function \(L(\theta )\)
\State evidence $Z \gets 0$
\State \(i \gets 0\)
\State prior mass sample $X_0  \gets 0$
\While{stopping condition not reached}
\State \(X_i \gets \exp(- i / N)\) 
\State \(L_i \gets \min(L(\theta _j))\)
\State \(Z \gets Z + L_i (X_{i-1} - X_{i+1}) / 2\)
\State replace the \(\theta _j\) corresponding to \(L_i\) with a new value, 
\State drawn from the prior restricted to \([L(\theta ) > L_i]\)
\State \(i \gets i+1\)
\EndWhile 
\State \(Z \gets Z + (X _{\text{last}} / N) \sum _{j} L(\theta _j)\) \\
\Return evidence \(Z\) \\
\Return all computed samples \(\theta _k\), weighted by \((X_{k-1} - X_{k+1}) / 2 \times L(\theta_k) / Z \).
\end{algorithmic}
\end{algorithm}

The stopping condition in algorithm \ref{alg:nested-sampling} must be defined so that it detects the point at which all the \(N\) points are lying very close to the maximum of the likelihood; this is typically done by setting a lower threshold for the likelihood improvement at each step. 

Besides estimating the evidence, this algorithm provides us with a sampling of the posterior distribution as long as we are careful to weigh them appropriately, as outlined in the last line of algorithm \ref{alg:nested-sampling}.

\section{Higher order waveforms}

The treatment of \ac{GW} production in linear gravity discussed in section \ref{sec:compact-binaries-linear} is useful but incomplete: as equation \eqref{eq:energy-emission-estimate} shows, the systems emitting the most are \emph{relativistic} (\(v/c\) is large) and \emph{compact} (\(R_s / R\) is large). 
This has been verified in practice by the fact by the binary systems we detected: mostly \acsp{BBH}, with some \acsp{BNS}.

The quadrupole approximation, as well as the linearization of gravity, breaks down in the case we are interested in: what to do? 

In the following sections we will discuss the main strategies\footnote{One strategy which is not particularly relevant in this work but which is useful in other contexts is the gravitational self-force approach \cite{waldIntroductionGravitationalSelfForce2009}, in which one works in orders of \(m_1 / m_2\), by making successive corrections to geodesic motion in a fixed background. This is not applicable to neutron stars, whose mass ratios are never extreme, but it is useful to discuss extreme mass ratio inspirals.} used to model \ac{CBC} waveforms during all of their stages. 

Qualitatively, a waveform from a \ac{CBC} involves a long \emph{inspiral} phase which terminates when the two compact bodies \emph{merge}, and finally a \emph{ringdown} phase in which the single body remaining exhibits damped vibrations.

\subsection{Post-Newtonian} \label{sec:post-newtonian}

The assumptions which we made in order to derive the quadrupole formula for the emission of gravitational radiation \eqref{eq:quadrupole-formula} were to consider a non-compact, slow-moving source (\(v \ll c\)), on a flat background. 

One might wish to expand the equations of motion in orders of \(v / c\), and this is the idea behind the \ac{PN} expansion, but there are technical difficulties associated with this. 
In terms of notation, a \(n\)PN expansion will be up to order \((v/c)^{2n}\) in this work.

\paragraph{Technical difficulties}

The strength of the gravitational field scales with the ratio of the Schwarzschild radius of an object to the distance between the objects, so as the system becomes relativistic in speed the gravity also becomes strong. 
The flat background metric needs to be substituted; a common choice is a Post-Minkowskian expansion, which is an expansion in orders of \(R_s / r\), where \(R_s\) is the Schwarzschild radius for the combined system. 
This expansion and the \ac{PN} one have different domains of validity (one far from the source, one near it), so one needs to find an \emph{overlap region} and match them.  

\acsp{GW} of low order source higher-order ones, as well as back-reacting and subtracting energy from the source. 
The latter of these effects comes about at the 2.5PN order: equating the emitted power estimated in equation \eqref{eq:energy-emission-estimate} to the derivative of the energy (which by the virial theorem has the same magnitude as the kinetic energy) \(\dot{E} = - M v \dot{v}\) we find  \(\dot{v} \propto (v/c)^{5}\). 

We can expand the retarded-time argument of the stress-energy tensor, \(t - r/c\), around \(r = 0\); this, however, is only valid if we are relatively near the source and breaks down if we try to extend the result to the ``radiation zone'' where our detector lies --- we need to treat that zone separately. 
This expansion allows us to express the Dalambertian as \(\square \approx \qty(1 + \order{(v/c)^2}) \nabla^2\), and to turn the Einstein equations into Poisson equations of the form 
%
\begin{align}
\triangle g_{\mu \nu }^{(n)} = \text{matter source} + \text{metric source from \(g_{\mu \nu}^{(n-1)}\)}
\,.
\end{align}

After computing the \(n\)PN equations of motion we will need to compute the appropriate number of terms in the multipole expansion \eqref{eq:gw-expansion-moments-stess-tensor}. 
This may also lead to divergencies: as we expand \( \frac{1}{\abs{\vec{x} - \vec{y}}}\) we get terms of type \((\vec{x} \cdot \vec{y} )^{\ell}\) with large values for \(\ell\), which rapidly diverge as we get further from the source. 
Specifically, the Poisson integrals, which solve \(g(\vec{x}) = \nabla^2 f(\vec{x})\) with 
%
\begin{align}
f(\vec{x}) = - \frac{1}{4 \pi } \int_{\mathbb{R}^3} \frac{ \dd[3]{y}}{\abs{\vec{x} - \vec{y}}} g(\vec{y})
\,
\end{align}
%
will not always converge.
Fortunately, this only reflects a limitation of the Poisson integral, and through analytic continuation one can recover a physical solution which respects the boundary conditions. 

Solutions to these problems have been developed between the '80s and the early 2000s, and currently there exist general formalisms, such as the Blanchet-Damour one, which allow for high-order computations of \ac{PN} waveforms \cite{blanchetGravitationalRadiationPostNewtonian2014}.

\paragraph{\ac{PN} waveforms}

The typical notation used for \ac{PN} waveforms expresses them \cite[sec.\ 5.6.1]{maggioreGravitationalWavesVolume2007} as a function of the dimensionless frequency
%
\begin{align}
x = \qty(\frac{GM \Omega }{c^3})^{2/3} = \order{(v/c)^2}
\marginnote{\(GM / r \sim v^2\) and \(r \Omega \sim v\).}
\,,
\end{align}
%
the symmetric mass ratio \(\nu = \mu / M\) and the dimensionless time 
%
\begin{align}
\Theta = \frac{\nu c^3}{5GM} (t_c - t)
\,.
\end{align}

These are related by \(x = \Theta^{-1/4} / 4\) (a reframing of equation \eqref{eq:gw-frequency-0PN}) at Newtonian order, and we can also write the phase as 
%
\begin{align}
\phi - \phi_0 &= - \frac{\Theta^{5/8}}{\nu } = - \frac{x^{-5/2}}{32 \nu }
\,.
\end{align}

Corrections to this expression are then written multiplicatively as a series in \(x\) (or, really, in \(x^{1/2}\), but the PN order is the exponent of \(x\)): 
%
\begin{align}
\phi - \phi_0 = - \frac{x^{5/2}}{32 \nu } \qty(1 + c_{\text{1PN}} x + c_{\text{1.5PN}} x^{1.5} + \dots)
\,.
\end{align}

% This expression for the phase diverges as \(\Theta \to 0\): this is unphysical, and we need to go to 2.5PN order to even just counteract this effect. 
The error in the phase is therefore of order \(x^{-1/2} \gg 1\) if we do not go beyond 2PN order: we need a high-order computation in order to recover an accurate expression for the phase. 
Current results include very high order waveforms, such as 5.5PN \cite[]{biniBinaryDynamicsFifth2020}.

\paragraph{The \ac{PN} order of tidal stresses}

We can give a crude estimate, which turns out to be accurate, for the \ac{PN} order at which the effects of quadrupolar tidal deformation come in \cite[pagg.\ 288--289]{maggioreGravitationalWavesVolume2007}. 

The quadrupole moment can be estimated as \(Q_{ij} \sim \epsilon mr^2\) where \(\epsilon \) is the induced ellipticity of the \ac{NS} while \(m\), \(r\) is its mass and radius.
This ellipticity comes from the tidal effect of the companion; it can be estimated as the ratio of the tidal force to the restoring self-gravity of the star: 
%
\begin{align}
\epsilon \sim \frac{F _{\text{tidal}}}{ F _{\text{self}}} \sim \frac{Gm r / d^3}{Gm / r^2} = \qty( \frac{r}{d})^3
\,,
\end{align}
%
where \(d\) is the separation between the two stars, and we assume that their masses are the same. 

The inter-body force induced by the quadrupolar deformation depends on the quadrupole moment like \cite[eqs.\ 5.219, 5.235]{maggioreGravitationalWavesVolume2007}
%
\begin{align}
F ^{\text{induced}}_k \approx Q_{ij} \partial_{i} \partial_{j} \partial_{k} U^{\text{Newton}} \sim \frac{Q_{ij}}{m} \partial_{i} \partial_{j} F^{\text{Newton}}_k \sim \qty( \frac{r}{d})^3 \frac{r^2}{d^2} F^{\text{Newton}}_k
\,,
\end{align}
%
so \(F^{\text{induced}} \sim (r/d)^{5} F^{\text{Newton}}\). 
This ratio can be reframed in terms of \(v/c\): the radius \(r\) of a star is proportional to its Schwarzschild radius \(Gm/c^2\); while the separation of the two is given by the virial theorem: \(m v^2 \sim Gm^2 /d\), so \(d \sim Gm / v^2\). This means that 
%
\begin{align}
F^{\text{induced}} \sim (v/c)^{10} F^{\text{Newton}}
\,,
\end{align}
%
and since the Newtonian order is the 0PN one tidal forces come in at 5PN order. 

While this is a very high order, the dimensionless tidal deformability parameters \(\Lambda \) are numerically large: therefore, it can be useful to include higher-order tidal terms in a lower-order calculation. 

The effect of spin-orbit interactions, on the other hand, comes about at 1.5PN order, while spin-spin interactions are a 2PN effect.

\subsection{Numerical Relativity} \label{sec:nr}

The \ac{PN} expansion, even if it goes to high order, is still not enough when we approach the merger. 

Thus, we need to compare our results to \ac{NR} simulations, in which the spacetime metric and the stress-energy tensor are evolved according to the Einstein equations. 
This is possible but time-consuming: each simulation requires many days of supercomputer time. 

The gravitational signal can be extracted from the simulated spacetime by computing the Weyl scalar \(\Psi_{4} = C_{\alpha \beta \gamma \delta }n^\alpha m^\beta n^\gamma m^\delta \),\footnote{Here \(C_{\alpha \beta \gamma \delta }\) is the Weyl tensor, the fully traceless part of the Riemann tensor, whose definition can be found for example in the book by \textcite[eq.\ 2.18]{gourgoulhonFormalismBasesNumerical2007}.} where \(n\) and \(m\) are component vectors of a null tetrad \cite[sec.\ 5.6.3]{lofflerEinsteinToolkitCommunity2012}. This scalar is related to gravitational wave emission by 
%
\begin{align}
\Psi_{4} = \ddot{h}_+ - i \ddot{h}_{\times }
\,.
\end{align}


The advantage is that we can incorporate the full machinery of \ac{GR}, and account for the internal dynamics of neutron stars, as well as other phenomena such as the formation of an accretion disk after the merger \cite{nedoraNumericalRelativitySimulations2020}.

Besides using the waveforms as validation for any model, 
an approach we can use for waveform generation is called ``\ac{IMR} phenomenological'': a \ac{PN} waveform is complemented with a power series fitted to \ac{NR} simulations \cite{kumarAccuracyPrecisionGravitationalwave2015}. 
Several variations on this idea are implemented in the \ac{LAL} \cite[]{ligoscientificcollaborationLIGOAlgorithmLibrary2018}.

\subsection{Effective One Body} \label{sec:eob}

The \ac{EOB} framework allows for the generation of waveforms encompassing inspiral, merger and ringdown, by mapping the relativistic two-body problem onto the motion of a test particle in an effective metric. 
This problem is described through an effective Hamiltonian, whose equations of motion are then numerically solved. 
Let us describe the procedure in a simplified case, including neither spin nor tidal interactions. 

The Hamiltonian of the real system is approximated with a \ac{PN} one, written in relative \ac{ADM} coordinates and made dimensionless \cite[eqs.\ 4--5]{damourGeneralRelativisticTwo2014}: 
%
\begin{align}
\hat{H} = \frac{H}{\mu } = \underbrace{\frac{p^2}{2} - \frac{1}{q}}_{\text{Newtonian}} 
+ \underbrace{\frac{1}{8} (3 \nu -1 ) (p^2)^2 - \frac{1}{2} \qty[(3+\nu ) p^2 + \nu (n \cdot p)^2] + \frac{1}{2 q^2}}_{\text{1PN}} + \dots
\,,
\end{align}
% 
where \(q\) and \(p\) are dimensionless variables related to relative distance and the corresponding
momentum by \(q = r c^2 / GM\) and \(p = p' / \mu \), where \(p'\) is the momentum with the correct dimensions.  

This is then matched\footnote{The way this ``matching'', this construction of a dictionary between the two- and the one-body problems, is performed is through a quantum-mechanical analogy. The idea is to consider the quantized energy levels corresponding to the classical Hamiltonians, which will depend on the quantum numbers \(n\) (principal quantum number) and \(\ell\) (total angular momentum),  while the quantum number \(m\), describing  the \(z\) component of the angular momentum, is irrelevant because of the spherical symmetry of the problem. One can then determine the correspondence by establishing a rule to translate between the energy levels corresponding to the same \((n, \ell)\) pairs \cite{damourGeneralRelativisticTwo2014}.} to the Hamiltonian of a particle moving in an effective metric 
%
\begin{align}
g _{\text{eff}} &= A(u, \nu ) \dd{T^2} + B(u, \nu) \dd{R^2} + R^2 \dd{\Omega^2}  \\
A(u, \nu ) &\approx 1 + \widetilde{a}_1 (\nu ) u + \widetilde{a}_2 (\nu ) u^2 + \dots  \\
B(u, \nu ) &\approx 1 + \widetilde{b}_1 (\nu ) u + \widetilde{b}_2 (\nu ) u^2 + \dots  
\,,
\end{align}
%
where \(u\) is the inverse radial coordinate \(u = GM / c^2 R\). 
The way to do so is to write both Hamiltonians in Delaunay (action-angle) coordinates. 
The metric potentials \(A\) and \(B\), to 3PN order, read: 
%
\begin{align}
A _{\text{3PN}} &= 1 - 2u + 3 \nu u^2 + \qty( \frac{94}{3} - \frac{41 \pi }{32}) \nu u^3  \\
B _{\text{3PN}} &= \frac{1 - 6 \nu u^2 + 2 (3 \nu - 26) \nu u^3}{A _{\text{3PN}}}
\,.
\end{align}

Note that the \(\nu \to 0\) case corresponds to one of the masses vanishing: therefore, we are looking at a test particle in Schwarzschild geometry, and we indeed recover \(A = 1-2u = 1/B\).
The other extreme case is \(\nu = 1/4\), which corresponds to \(m_1 = m_2 \). 

A strategy which is then used is Pad resummation: 
the idea is to take a Taylor expansion (such as those for the \ac{PN} potentials) and match it to 
a ratio of polynomial functions, so that 
%
\begin{align}
f^{(N)}(x) = \sum _{n=1}^{N} c_n x^{n} \approx P_{L}^{M}[f^{(n)}(x)] = \frac{\sum _{n=1}^{M} a_n x^{n}}{\sum _{n=1}^{L} b_n x^{n}}
\,,
\end{align}
%
where the coefficients \(c_n\) are fixed, while the \(a_n\) and \(b_n\) are determined algebraically 
by having equal-order terms match in the two series. 

A Pad approximant \(P_{L}^{M}\) can then be applied to any polynomial function. 
This may seem pointless, since it reproduces the \ac{PN} result at the same order, however in practice the Pad-resummed expression often exhibits desirable behaviours, such as avoiding divergences or having faster convergence to the true potential. 

The Hamiltonian whose equations of motion are actually solved is expressed in terms of the potentials \cite[eq.\ 8.22]{bernuzziNotesGravitationalWaves2021}:  
%
\begin{align}
H _{\text{EOB}} &= Mc^2 \sqrt{1 + 2 \nu (\hat{H} _{\text{eff}} - 1 )}  \\
\hat{H} _{\text{eff}} = \frac{H_{\text{eff}}}{\mu } &= 
\sqrt{ A(u, \nu ) \qty(1 + p^2_{\phi } u^2 + 2 \nu (4-3 \nu ) u^2 p^{4}_{r*}) + p^2_{r*}}
\,,
\end{align}
%
where \(p_{r*} = \mu^{-1} \int (B/A) \dd{R} \) is the momentum corresponding to a rescaled radial variable, while \(p_\varphi = P_\varphi / (\mu GM)\) is a rescaled angular momentum. 

% \textcite{schaferHamiltonianFormulationGeneral2018}

% \textcite{damourComparisonSearchTemplates2005}

This formalism can then be complemented by including some further elements: one is the radiation reaction force, which can be expressed as an influence decreasing the momentum \(p_\varphi \) according to the emitted flux.
Including this term means we are not considering an \emph{adiabatic} approximation anymore. 

Further, next-to-quasi-circular terms are introduced: these are multiplicative corrections to the last orbits which account for the fact that these are getting further and further from being circular. 
Finally, the waveform is smoothly connected to a model for the ringdown, which is informed by \ac{BH} perturbation theory and \ac{NR} simulations. 

\ac{EOB} models can also incorporate tidal and spin effects: the model \texttt{TEOBResumS} \cite{nagarTimedomainEffectiveonebodyGravitational2018} is applicable to spin-aligned, tidally interacting compact objects. 

These \ac{EOB} models can reproduce \ac{NR} results quite well: for example, in the case of spinning \ac{BBH} binaries 
\textcite[fig.\ 2]{nagarAllOneEffective2021} find mismatches between the \ac{EOB} and \acp{GW} from \ac{NR} simulations to be at most of the order of \(F \sim 10^{-2}\) and typically even less, \(F \sim 10^{-3}\).

% \begin{figure}[ht]
% \centering
% \includegraphics[width=\textwidth]{figures/TEOBResumSPA_evaluation}
% \caption{Evaluation times for one waveform using the \texttt{TEOBResumS} \ac{EOB} model. In one case shown, a \ac{SPA} is used to move to the frequency domain; in the other the waveform is computed in the time domain. The time-domain model is not slower in and of itself: it has to output longer and longer waveforms, since the time and frequency grid spacings are kept constant.}
% \label{fig:TEOBResumSPA_evaluation}
% \end{figure}

The \ac{EOB} models natively output time-domain waveforms, while as discussed in section \ref{sec:data-analysis} we need them in the frequency domain in order to perform data analysis. 
\texttt{TEOBResumS} implements the \ac{SPA} in order to quickly output frequency-domain waveforms \cite[]{gambaFastFaithfulFrequencydomain2020}.

% One must therefore find a way to move to the frequency domain. An option is to use a \ac{SPA} \cite{gambaFastFaithfulFrequencydomain2020}; this has been found to be quite successful in providing fast waveform evaluations even for low initial frequencies. 
%as can be seen in figure \ref{fig:TEOBResumSPA_evaluation}. 
% However, it is still an approximation: ideally, we would want to numerically Fourier-transform the time-domain waveform. 
% The issues with  

% In order to perform a \ac{FFT}, we need equally-spaced points in time, so the full duration needs to be densely sampled; also, the merger moment needs to be resolved by the sampling density. 
% This constrains the sampling rate to be quite high, therefore the size of the array representing the time-domain waveform will be quite large, slowing down the computation. 

% The model \ac{mb} is an attempt to mitigate this problem, by pre-generating Fourier-transformed waveforms. 


\end{document}
